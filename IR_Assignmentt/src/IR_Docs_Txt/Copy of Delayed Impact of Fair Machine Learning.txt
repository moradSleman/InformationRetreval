Delayed Impact of Fair Machine Learning
Lydia T. Liuâˆ—

Sarah Deanâˆ—

Esther Rolfâˆ—

Max Simchowitzâˆ—

Moritz Hardtâˆ—

arXiv:1803.04383v2 [cs.LG] 7 Apr 2018

April 10, 2018

Abstract
Fairness in machine learning has predominantly been studied in static classification settings
without concern for how decisions change the underlying population over time. Conventional
wisdom suggests that fairness criteria promote the long-term well-being of those groups they
aim to protect.
We study how static fairness criteria interact with temporal indicators of well-being, such
as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate
that even in a one-step feedback model, common fairness criteria in general do not promote
improvement over time, and may in fact cause harm in cases where an unconstrained objective
would not. We completely characterize the delayed impact of three standard criteria, contrasting
the regimes in which these exhibit qualitatively different behavior. In addition, we find that
a natural form of measurement error broadens the regime in which fairness criteria perform
favorably.
Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.

1

Introduction

Machine learning commonly considers static objectives defined on a snapshot of the population
at one instant in time; consequential decisions, in contrast, reshape the population over time.
Lending practices, for example, can shift the distribution of debt and wealth in the population.
Job advertisements allocate opportunity. School admissions shape the level of education in a
community.
Existing scholarship on fairness in automated decision-making criticizes unconstrained machine
learning for its potential to harm historically underrepresented or disadvantaged groups in the
population [Executive Office of the President, 2016, Barocas and Selbst, 2016]. Consequently, a
variety of fairness criteria have been proposed as constraints on standard learning objectives. Even
though, in each case, these constraints are clearly intended to protect the disadvantaged group by
an appeal to intuition, a rigorous argument to that effect is often lacking.
In this work, we formally examine under what circumstances fairness criteria do indeed promote
the long-term well-being of disadvantaged groups measured in terms of a temporal variable of
interest. Going beyond the standard classification setting, we introduce a one-step feedback model
of decision-making that exposes how decisions change the underlying population over time.
âˆ—

Department of Electrical Engineering and Computer Sciences, University of California, Berkeley

1

Our running example is a hypothetical lending scenario. There are two groups in the population
with features described by a summary statistic, such as a credit score, whose distribution differs
between the two groups. The bank can choose thresholds for each group at which loans are offered.
While group-dependent thresholds may face legal challenges [Ross and Yinger, 2006], they are
generally inevitable for some of the criteria we examine. The impact of a lending decision has
multiple facets. A default event not only diminishes profit for the bank, it also worsens the financial
situation of the borrower as reflected in a subsequent decline in credit score. A successful lending
outcome leads to profit for the bank and also to an increase in credit score for the borrower.
When thinking of one of the two groups as disadvantaged, it makes sense to ask what lending
policies (choices of thresholds) lead to an expected improvement in the score distribution within
that group. An unconstrained bank would maximize profit, choosing thresholds that meet a breakeven point above which it is profitable to give out loans. One frequently proposed fairness criterion,
sometimes called demographic parity, requires the bank to lend to both groups at an equal rate.
Subject to this requirement the bank would continue to maximize profit to the extent possible.
Another criterion, originally called equality of opportunity, equalizes the true positive rates between
the two groups, thus requiring the bank to lend in both groups at an equal rate among individuals
who repay their loan. Other criteria are natural, but for clarity we restrict our attention to these
three.
Do these fairness criteria benefit the disadvantaged group? When do they show a clear advantage
over unconstrained classification? Under what circumstances does profit maximization work in the
interest of the individual? These are important questions that we begin to address in this work.

1.1

Contributions

We introduce a one-step feedback model that allows us to quantify the long-term impact of classification on different groups in the population. We represent each of the two groups A and B by a
score distribution Ï€ A and Ï€ B , respectively. The support of these distributions is a finite set X corresponding to the possible values that the score can assume. We think of the score as highlighting
one variable of interest in a specific domain such that higher score values correspond to a higher
probability of a positive outcome. An institution chooses selection policies Ï„ A , Ï„ B : X â†’ [0, 1] that
assign to each value in X a number representing the rate of selection for that value. In our example,
these policies specify the lending rate at a given credit score within a given group. The institution
will always maximize their utility (defined formally later) subject to either (a) no constraint, or (b)
equality of selection rates, or (c) equality of true positive rates.
We assume the availability of a function âˆ† : X â†’ R such that âˆ†(x) provides the expected
change in score for a selected individual at score x. The central quantity we study is the expected
difference in the mean score in group j âˆˆ {A, B} that results from an institutions policy, âˆ†Âµj
defined formally in Equation (2). When modeling the problem, the expected mean difference can
also absorb external factors such as â€œreversion to the meanâ€ so long as they are mean-preserving.
Qualitatively, we distinguish between long-term improvement (âˆ†Âµj > 0), stagnation (âˆ†Âµj = 0),
and decline (âˆ†Âµj < 0). Our findings can be summarized as follows:
1. Both fairness criteria (equal selection rates, equal true positive rates) can lead to all possible
outcomes (improvement, stagnation, and decline) in natural parameter regimes. We provide
a complete characterization of when each criterion leads to each outcome in Section 3.

2

â€¢ There are a class of settings where equal selection rates cause decline, whereas equal
true positive rates do not (Corollary 3.5),
â€¢ Under a mild assumption, the institutionâ€™s optimal unconstrained selection policy can
never lead to decline (Proposition 3.1).
2. We introduce the notion of an outcome curve (Figure 1) which succinctly describes the different regimes in which one criterion is preferable over the others.
3. We perform experiments on FICO credit score data from 2003 and show that under various
models of bank utility and score change, the outcomes of applying fairness criteria are in line
with our theoretical predictions.
4. We discuss how certain types of measurement error (e.g., the bank underestimating the repayment ability of the disadvantaged group) affect our comparison. We find that measurement
error narrows the regime in which fairness criteria cause decline, suggesting that measurement
should be a factor when motivating these criteria.
5. We consider alternatives to hard fairness constraints.
â€¢ We evaluate the optimization problem where fairness criterion is a regularization term
in the objective. Qualitatively, this leads to the same findings.
â€¢ We discuss the possibility of optimizing for group score improvement âˆ†Âµj directly subject
to institution utility constraints. The resulting solution provides an interesting possible
alternative to existing fairness criteria.
We focus on the impact of a selection policy over a single epoch. The motivation is that the
designer of a system usually has an understanding of the time horizon after which the system
is evaluated and possibly redesigned. Formally, nothing prevents us from repeatedly applying our
model and tracing changes over multiple epochs. In reality, however, it is plausible that over greater
time periods, economic background variables might dominate the effect of selection.
Reflecting on our findings, we argue that careful temporal modeling is necessary in order to
accurately evaluate the impact of different fairness criteria on the population. Moreover, an understanding of measurement error is important in assessing the advantages of fairness criteria relative
to unconstrained selection. Finally, the nuances of our characterization underline how intuition
may be a poor guide in judging the long-term impact of fairness constraints.

1.2

Related work

Recent work by Hu and Chen [2018] considers a model for long-term outcomes and fairness in
the labor market. They propose imposing the demographic parity constraint in a temporary labor
market in order to provably achieve an equitable long-term equilibrium in the permanent labor
market, reminiscent of economic arguments for affirmative action [Foster and Vohra, 1992]. The
equilibrium analysis of the labor market dynamics model allows for specific conclusions relating
fairness criteria to long term outcomes. Our general framework is complementary to this type of
domain specific approach.
Fuster et al. [2017] consider the problem of fairness in credit markets from a different perspective.
Their goal is to study the effect of machine learning on interest rates in different groups at an
equilibrium, under a static model without feedback.
3

Ensign et al. [2017] consider feedback loops in predictive policing, where the police more heavily
monitor high crime neighborhoods, thus further increasing the measured number of crimes in those
neighborhoods. While the work addresses an important temporal phenomenon using the theory of
urns, it is rather different from our one-step feedback model both conceptually and technically.
Demographic parity and its related formulations have been considered in numerous papers [e.g.
Calders et al., 2009, Zafar et al., 2017]. Hardt et al. [2016] introduced the equality of opportunity
constraint that we consider and demonstrated limitations of a broad class of criteria. Kleinberg
et al. [2017] and Chouldechova [2016] point out the tension between â€œcalibration by groupâ€ and
equal true/false positive rates. These trade-offs carry over to some extent to the case where we
only equalize true positive rates [Pleiss et al., 2017].
A growing literature on fairness in the â€œbanditsâ€ setting of learning [see Joseph et al., 2016,
et sequelae] deals with online decision making that ought not to be confused with our one-step
feedback setting. Finally, there has been much work in the social sciences on analyzing the effect
of affirmative action [see e.g., Keith et al., 1985, Kalev et al., 2006].

1.3

Discussion

In this paper, we advocate for a view toward long-term outcomes in the discussion of â€œfairâ€ machine
learning. We argue that without a careful model of delayed outcomes, we cannot foresee the impact
a fairness criterion would have if enforced as a constraint on a classification system. However, if
such an accurate outcome model is available, we show that there are more direct ways to optimize
for positive outcomes than via existing fairness criteria. We outline such an outcome-based solution
in Section 4.3. Specifically, in the credit setting, the outcome-based solution corresponds to giving
out more loans to the protected group in a way that reduces profit for the bank compared to
unconstrained profit maximization, but avoids loaning to those who are unlikely to benefit, resulting
in a maximally improved group average credit score. The extent to which such a solution could
form the basis of successful regulation depends on the accuracy of the available outcome model.
This raises the question if our model of outcomes is rich enough to faithfully capture realistic
phenomena. By focusing on the impact that selection has on individuals at a given score, we model
the effects for those not selected as zero-mean. For example, not getting a loan in our model
has no negative effect on the credit score of an individual.1 This does not mean that wrongful
rejection (i.e., a false negative) has no visible manifestation in our model. If a classifier has a
higher false negative rate in one group than in another, we expect the classifier to increase the
disparity between the two groups (under natural assumptions). In other words, in our outcomebased model, the harm of denied opportunity manifests as growing disparity between the groups.
The cost of a false negative could also be incorporated directly into the outcome-based model by a
simple modification (see Footnote 2). This may be fitting in some applications where the immediate
impact of a false negative to the individual is not zero-mean, but significantly reduces their future
success probability.
In essence, the formalism we propose requires us to understand the two-variable causal mechanism that translates decisions to outcomes. This can be seen as relaxing the requirements compared
with recent work on avoiding discrimination through causal reasoning that often required stronger
assumptions [Kusner et al., 2017, Nabi and Shpitser, 2017, Kilbertus et al., 2017]. In particular,
these works required knowledge of how sensitive attributes (such as gender, race, or proxies thereof)
1

In reality, a denied credit inquiry may lower oneâ€™s credit score, but the effect is small compared to a default event.

4

causally relate to various other variables in the data. Our model avoids the delicate modeling step
involving the sensitive attribute, and instead focuses on an arguably more tangible economic mechanism. Nonetheless, depending on the application, such an understanding might necessitate greater
domain knowledge and additional research into the specifics of the application. This is consistent
with much scholarship that points to the context-sensitive nature of fairness in machine learning.

2

Problem Setting

We consider two groups A and B, which comprise a gA and gB = 1 âˆ’ gA fraction of the total
population, and an institution which makes a binary decision for each individual in each group,
called selection. Individuals in each group are assigned scores in X := [C], and the scores for
group j âˆˆ {A, B} are distributed according Ï€ j âˆˆ SimplexCâˆ’1 . The institution selects a policy
Ï„ := (Ï„ A , Ï„ B ) âˆˆ [0, 1]2C , where Ï„ j (x) corresponds to the probability the institution selects an
individual in group j with score x. One should think of a score as an abstract quantity which
summarizes how well an individual is suited to being selected; examples are provided at the end of
this section.
We assume that the institution is utility-maximizing, but may impose certain constraints to
ensure that the policy Ï„ is fair, in a sense described in Section 2.2. We assume that there exists a
function u : C â†’ R, such that the institutionâ€™s expected utility for a policy Ï„ is given by
P
P
U(Ï„ ) = jâˆˆ{A,B} gj xâˆˆX Ï„ j (x)Ï€ j (x)u(x).
(1)
Novel to this work, we focus on the effect of the selection policy Ï„ on the groups A and B. We
quantify these outcomes in terms of an average effect that a policy Ï„ j has on group j. Formally, for
a function âˆ†(x) : X â†’ R, we define the average change of the mean score Âµj for group j
P
(2)
âˆ†Âµj (Ï„ ) := xâˆˆX Ï€ j (x)Ï„ j (x)âˆ†(x) .
We remark that many of our results also go through if âˆ†Âµj (Ï„ ) simply refers to an abstract change
in well-being, not necessarily a change in the mean score. Furthermore, it is possible to modify the
definition of âˆ†Âµj (Ï„ ) such that it directly considers outcomes of those who are not selected.2 Lastly,
we assume that the success of an individual is independent of their group given the score; that is,
the score summarizes all relevant information about the success event, so there exists a function
Ï : X â†’ [0, 1] such that individuals of score x succeed with probability Ï(x).
We now introduce the specific domain of credit scores as a running example in the rest of
the paper, after which we present two more examples showing the general applicability of our
formulation to many domains.
Example 2.1 (Credit scores). In the setting of loans, scores x âˆˆ [C] represent credit scores, and the
bank serves as the institution. The bank chooses to grant or refuse loans to individuals according
to a policy Ï„ . Both bank and personal utilities are given as functions of loan repayment, and
2

If we consider functions âˆ†p (x) : X â†’ P
R and âˆ†n (x) : X â†’ R to represent the average effect of selection and
non-selection respectively, then âˆ†Âµj (Ï„ ) :=
model corresponds
xâˆˆX Ï€ j (x) (Ï„ j (x)âˆ†p (x) + (1 âˆ’ Ï„ j (x))âˆ†n (x)). This P
to replacing âˆ†(x) in the original outcome definition with âˆ†p (x) âˆ’ âˆ†n (x), and adding a offset xâˆˆX Ï€ j (x)âˆ†n (x).
Under the assumption that âˆ†p (x) âˆ’ âˆ†n (x) increases in x, this model gives rise to outcomes curves resembling those
in Figure 1 up to vertical translation. All presented results hold unchanged under the further assumption that
âˆ†Âµ(Î² MaxUtil ) â‰¥ 0.

5

therefore depend on the success probabilities Ï(x), representing the probability that any individual
with credit score x can repay a loan within a fixed time frame. The expected utility to the bank
is given by the expected return from a loan, which can be modeled as an affine function of Ï(x):
u(x) = u+ Ï(x) + uâˆ’ (1 âˆ’ Ï(x)), where u+ denotes the profit when loans are repaid and uâˆ’ the loss
when they are defaulted on. Individual outcomes of being granted a loan are based on whether
or not an individual repays the loan, and a simple model for âˆ†(x) may also be affine in Ï(x):
âˆ†(x) = c+ Ï(x) + câˆ’ (1 âˆ’ Ï(x)), modified accordingly at boundary states. The constant c+ denotes
the gain in credit score if loans are repaid and câˆ’ is the score penalty in case of default.
Example 2.2 (Advertising). A second illustrative example is given by the case of advertising
agencies making decisions about which groups to target. An individual with product interest score
x responds positively to an ad with probability Ï(x). The ad agency experiences utility u(x) related
to click-through rates, which increases with Ï(x). Individuals who see the ad but are uninterested
may react negatively (becoming less interested in the product), and âˆ†(x) encodes the interest
change. If the product is a positive good like education or employment opportunities, interest can
correspond to well-being. Thus the advertising agencyâ€™s incentives to only show ads to individuals
with extremely high interest may leave behind groups whose interest is lower on average. A related
historical example occurred in advertisements for computers in the 1980s, where male consumers
were targeted over female consumers, arguably contributing to the current gender gap in computing.
Example 2.3 (College Admissions). The scenario of college admissions or scholarship allotments
can also be considered within our framework. Colleges may select certain applicants for acceptance
according to a score x, which could be thought encode a â€œcollege preparednessâ€ measure. The students who are admitted might â€œsucceedâ€ (this could be interpreted as graduating, graduating with
honors, finding a job placement, etc.) with some probability Ï(x) depending on their preparedness.
The college might experience a utility u(x) corresponding to alumni donations, or positive rating
when a student succeeds; they might also show a drop in rating or a loss of invested scholarship
money when a student is unsuccessful. The studentâ€™s success in college will affect their later success,
which could be modeled generally by âˆ†(x). In this scenario, it is challenging to ensure that a single
summary statistic x captures enough information about a student; it may be more appropriate to
consider x as a vector as well as more complex forms of Ï(x).
While a variety of applications are modeled faithfully within our framework, there are limitations
to the accuracy with which real-life phenomenon can be measured by strictly binary decisions and
success probabilities. Such binary rules are necessary for the definition and execution of existing
fairness criteria, (see Sec. 2.2) and as we will see, even modeling these facets of decision making as
binary allows for complex and interesting behavior.

2.1

The Outcome Curve

We now introduce important outcome regimes, stated in terms of the change in average group
score. A policy (Ï„ A , Ï„ B ) is said to cause active harm to group j if âˆ†Âµj (Ï„ j ) < 0, stagnation if
âˆ†Âµj (Ï„ j ) = 0, and improvement if âˆ†Âµj (Ï„ j ) > 0. Under our model, MaxUtil policies can be chosen
in a standard fashion which applies the same threshold Ï„ MaxUtil for both groups, and is agnostic to
the distributions Ï€ A and Ï€ B . Hence, if we define
âˆ†ÂµMaxUtil
:= âˆ†Âµj (Ï„ MaxUtil )
j
6

(3)

OUTCOME CURVE
Relative Improvement
Relative Harm
Active Harm

0

Selection Rate

1

(b)

0

1

*

0

Selection Rate

1

Selection Rate
(c)

(a)

Figure 1: The above figure shows the outcome curve. The horizontal axis represents the selection
rate for the population; the vertical axis represents the mean change in score. (a) depicts the full
spectrum of outcome regimes, and colors indicate regions of active harm, relative harm, and no
harm. In (b): a group that has much potential for gain, in (c): a group that has no potential for
gain.
we say that a policy causes relative harm to group j if âˆ†Âµj (Ï„ j ) < âˆ†ÂµMaxUtil
, and relative imj
MaxUtil
provement if âˆ†Âµj (Ï„ j ) > âˆ†Âµj
. In particular, we focus on these outcomes for a disadvantaged
group, and consider whether imposing a fairness constraint improves their outcomes relative to the
MaxUtil strategy. From this point forward, we take A to be disadvantaged or protected
group.
P
Figure 1 displays the important outcome regimes in terms of selection rates Î²j := xâˆˆX Ï€ j (x)Ï„ j (x).
This succinct characterization is possible when considering decision rules based on (possibly randomized) score thresholding, in which all individuals with scores above a threshold are selected. In
Section 5, we justify the restriction to such threshold policies by showing it preserves optimality.
In Section 5.1, we show that the outcome curve is concave, thus implying that it takes the shape
depicted in Figure 1. To explicitly connect selection rates to decision policies, we define the rate
function rÏ€ (Ï„ j ) which returns the proportion of group j selected by the policy. We show that this
function is invertible for a suitable class of threshold policies, and in fact the outcome curve is
âˆ’1 (Î²)). Next, we define
precisely the graph of the map from selection rate to outcome Î² 7â†’ âˆ†ÂµA (rÏ€
A
the values of Î² that mark boundaries of the outcome regions.
Definition 2.1 (Selection rates of interest). Given the protected group A, the following selection
rates are of interest in distinguishing between qualitatively different classes of outcomes (Figure
1). We define Î² MaxUtil as the selection rate for A under MaxUtil; Î²0 as the harm threshold, such
âˆ’1 (Î² )) = 0; Î² âˆ— as the selection rate such that âˆ†Âµ is maximized; Î² as the outcomethat âˆ†ÂµA (rÏ€
0
A
A
âˆ’1 (Î²)) = âˆ†Âµ (r âˆ’1 (Î² MaxUtil )) with Î² > Î² MaxUtil .
complement of the MaxUtil selection rate, âˆ†ÂµA rÏ€
A Ï€A
A

7

2.2

Decision Rules and Fairness Criteria

We will consider policies that maximize the institutionâ€™s total expected utility, potentially subject
to a constraint: Ï„ âˆˆ C âˆˆ [0, 1]2C which enforces some notion of â€œfairnessâ€. Formally, the institution
selects Ï„âˆ— âˆˆ argmax U(Ï„ ) s.t. Ï„ âˆˆ C. We consider the three following constraints:
Definition 2.2 (Fairness criteria). The maximum utility (MaxUtil) policy corresponds to the nullconstraint C = [0, 1]2C , so that the institution is free to focus solely on utility. The demographic
parity (DemParity)
rates between both groups. Formally, the
 policy results
P in equal selection
P
constraint is C = (Ï„ A , Ï„ B ) : xâˆˆX Ï€ A (x)Ï„ A = xâˆˆX Ï€ B (x)Ï„ B . The equal opportunity (EqOpt)
policy resultsPin equal true positive rates (TPR) between both group, where TPR is defined as
xâˆˆX Ï€ j (x)Ï(x)Ï„ (x)
TPRj (Ï„ ) := P
. EqOpt ensures that the conditional probability of selection given
xâˆˆX Ï€ j (x)Ï(x)
that the individual will be successful is independent of the population, formally enforced by the
constraint C = {(Ï„ A , Ï„ B ) : TPRA (Ï„ A ) = TPRB (Ï„ B )} .
Just as the expected outcome âˆ†Âµ can be expressed in terms of selection rate for threshold
policies, so can the total utility U. In the unconstrained cause, U varies independently over the
selection rates for group A and B; however, in the presence of fairness constraints the selection rate
for one group determines the allowable selection rate for the other. The selection rates must be equal
for DemParity, but for EqOpt we can define a transfer function, G(Aâ†’B) , which for every loan rate
Î² in group A gives the loan rate in group B that has the same true positive rate. Therefore, when
considering threshold policies, decision rules amount to maximizing functions of single parameters.
This idea is expressed in Figure 2, and underpins the results to follow.

3

Results

In order to clearly characterize the outcome of applying fairness constraints, we make the following
assumption.
Assumption 1 (Institution utilities). The institutionâ€™s individual utility function is more stringent
than the expected score changes, u(x) > 0 =â‡’ âˆ†(x) > 0. (For the linear form presented in
Example 2.1, uuâˆ’
< ccâˆ’
is necessary and sufficient.)
+
+
This simplifying assumption quantifies the intuitive notion that institutions take a greater risk
by accepting than the individual does by applying. For example, in the credit setting, a bank loses
the amount loaned in the case of a default, but makes only interest in case of a payback. Using
Assumption 1, we can restrict the position of MaxUtil on the outcome curve in the following sense.
Proposition 3.1 (MaxUtil does not cause active harm). Under Assumption 1, 0 â‰¤ âˆ†ÂµMaxUtil â‰¤
âˆ†Âµâˆ— .
We direct the reader to Appendix C for the proof of the above proposition, and all subsequent
results presented in this section. The results are corollaries to theorems presented in Section 6.

3.1

Prospects and Pitfalls of Fairness Criteria

We begin by characterizing general settings under which fairness criteria act to improve outcomes
over unconstrained MaxUtil strategies. For this result, we will assume that group A is disadvantaged
8

1

0

MU
DP
EO

0

1
Selection Rate

Figure 2: Both outcomes âˆ†Âµ and institution utilities U can be plotted as a function of selection
rate for one group. The maxima of the utility curves determine the selection rates resulting from
various decision rules.
in the sense that the MaxUtil acceptance rate for B is large compared to relevant acceptance rates
for A.
Corollary 3.2 (Fairness Criteria can cause Relative Improvement). (a) Under the assumption that
Î²AMaxUtil < Î² and Î²BMaxUtil > Î²AMaxUtil , there exist population proportions g0 < g1 < 1 such that, for
DemParity
< Î². That is, DemParity causes relative improvement.
all gA âˆˆ [g0 , g1 ], Î²AMaxUtil < Î²A
(b) Under the assumption that there exist Î²AMaxUtil < Î² < Î² 0 < Î² such that Î²BMaxUtil >
G(Aâ†’B) (Î²), G(Aâ†’B) (Î² 0 ), there exist population proportions g2 < g3 < 1 such that, for all gA âˆˆ
EqOpt
< Î². That is, EqOpt causes relative improvement.
[g2 , g3 ], Î²AMaxUtil < Î²A
This result gives the conditions under which we can guarantee the existence of settings in which
fairness criteria cause improvement relative to MaxUtil. Relying on machinery proved in Section 6,
the result follows from comparing the position of optima on the utility curve to the outcome curve.
Figure 2 displays a illustrative example of both the outcome curve and the institutionsâ€™ utility U
as a function of the selection rates in group A. In the utility function (1), the contributions of each
group are weighted by their population proportions gj , and thus the resulting selection rates are
sensitive to these proportions.
As we see in the remainder of this section, fairness criteria can achieve nearly any position
along the outcome curve under the right conditions. This fact comes from the potential mismatch
between the outcomes, controlled by âˆ†, and the institutionâ€™s utility u.
The next theorem implies that DemParity can be bad for long term well-being of the protected
group by being over-generous, under the mild assumption that âˆ†ÂµA (Î²BMaxUtil ) < 0:
Corollary 3.3 (DemParity can cause harm by being over-eager). Fix a selection rate Î². Assume
that Î²BMaxUtil > Î² > Î²AMaxUtil . Then, there exists a population proportion g0 such that, for all
DemParity
gA âˆˆ [0, g0 ], Î²A
> Î². In particular, when Î² = Î²0 , DemParity causes active harm, and when
Î² = Î², DemParity causes relative harm.
9

The assumption âˆ†ÂµA (Î²BMaxUtil ) < 0 implies that a policy which selects individuals from group
A at the selection rate that MaxUtil would have used for group B necessarily lowers average score
in A. This is one natural notion of protected group Aâ€™s â€˜disadvantageâ€™ relative to group B. In this
case, DemParity penalizes the scores of group A even more than a naive MaxUtil policy, as long as
group proportion gA is small enough. Again, small gA is another notion of group disadvantage.
Using credit scores as an example, Corollary 3.3 tells us that an overly aggressive fairness
criterion will give too many loans to people in a protected group who cannot pay them back,
hurting the groupâ€™s credit scores on average. In the following theorem, we show that an analogous
result holds for EqOpt.
Corollary 3.4 (EqOpt can cause harm by being over-eager). Suppose that Î²BMaxUtil > G(Aâ†’B) (Î²)
and Î² > Î²AMaxUtil . Then, there exists a population proportion g0 such that, for all gA âˆˆ [0, g0 ],
EqOpt
Î²A
> Î². In particular, when Î² = Î²0 , EqOpt causes active harm, and when Î² = Î², EqOpt
causes relative harm.
We remark that in Corollary 3.4, we rely on the transfer function, G(Aâ†’B) , which for every loan
rate Î² in group A gives the loan rate in group B that has the same true positive rate. Notice that
if G(Aâ†’B) were the identity function, Corollary 3.3 and Corollary 3.4 would be exactly the same.
Indeed, our framework (detailed in Section 6 and Appendix B) unifies the analyses for a large class
of fairness constraints that includes DemParity and EqOpt as specific cases, and allows us to derive
results about impact on âˆ†Âµ using general techniques. In the next section, we present further results
that compare the fairness criteria, demonstrating the usefulness of our technical framework.

3.2

Comparing EqOpt and DemParity

Our analysis of the acceptance rates of EqOpt and DemParity in Section 6 suggests that it is
difficult to compare DemParity and EqOpt without knowing the full distributions Ï€ A , Ï€ B , which is
necessary to compute the transfer function G(Aâ†’B) . In fact, we have found that settings exist both
in which DemParity causes harm while EqOpt causes improvement and in which DemParity causes
improvement while EqOpt causes harm. There cannot be one general rule as to which fairness
criteria provides better outcomes in all settings. We now present simple sufficient conditions on the
geometry of the distributions for which EqOpt is always better than DemParity in terms of âˆ†ÂµA .
Corollary 3.5 (EqOpt may avoid active harm where DemParity fails). Fix a selection rate Î².
Suppose Ï€ A , Ï€ B are identical up to a translation with ÂµA < ÂµB , i.e. Ï€ A (x) = Ï€ B (x + (ÂµB âˆ’ ÂµA )).
For simplicity, take Ï(x) to be linear in x. Suppose
X
Î²>
Ï€A.
x>ÂµA

Then there exists an interval [g1 , g2 ] âŠ† [0, 1], such that âˆ€gA > g1 , Î² EqOpt < Î² while âˆ€gA < g2 ,
Î² DemParity > Î². In particular, when Î² = Î²0 , this implies DemParity causes active harm but EqOpt
causes improvement for gA âˆˆ [g1 , g2 ], but for any gA such that DemParity causes improvement,
EqOpt also causes improvement.
ToPinterpret the conditions under which Corollary
3.5 holds, consider when we might have
P
Î²0 > x>ÂµA Ï€ A . This is precisely when âˆ†ÂµA ( x>ÂµA Ï€ A ) > 0, that is, âˆ†ÂµA > 0 for a policy that
selects every individual whose score is above the group A mean, which is reasonable in reality.
10

Indeed, the converse would imply that group A has such low scores that even selecting all above
average individuals in A would hurt the average score. In such a case, Corollary 3.5 suggests that
EqOpt is better than DemParity at avoiding active harm, because it is more conservative. A natural
question then is: can EqOpt cause relative harm by being too stingy?
Corollary 3.6 (DemParity never loans less than MaxUtil, but EqOpt might). Recall the definition
of the TPR functions TPRj , and suppose that the MaxUtil policy Ï„ MaxUtil is such that
Î²AMaxUtil < Î²BMaxUtil and TPRA (Ï„ MaxUtil ) > TPRB (Ï„ MaxUtil )
EqOpt

DemParity

Then Î²A
< Î²AMaxUtil < Î²A
lower than MaxUtil.

(4)

. That is, EqOpt causes relative harm by selecting at a rate

The above theorem shows that DemParity is never stingier than MaxUtil to the protected group
A, as long as a A is disadvantaged in the sense that MaxUtil selects a larger proportion of B than A.
On the other hand, EqOpt can select less of group A than MaxUtil, and by definition, cause relative
harm. This is a surprising result about EqOpt, and this phenomenon arises from high levels of ingroup inequality for group A. Moreover, we show in Appendix C that there are parameter settings
where the conditions in Corollary 3.6 are satisfied even under a stringent notion of disadvantage
we call CDF domination, described therein.

4
4.1

Relaxations of Constrained Fairness
Regularized fairness

In many cases, it may be unrealistic for an institution to ensure that fairness constraints are met
exactly. However, one can consider â€œsoftâ€ formulations of fairness constraints which either penalized
the differences in acceptance rate (DemParity) or the differences in TPR (EqOpt). In Appendix B,
we formulate these soft constraints as regularized objectives. For example, a soft-DemParity can
be rendered as
max U(Ï„ ) âˆ’ Î»Î¦(hÏ€ A , Ï„ A i âˆ’ hÏ€ B , Ï„ B i) ,

Ï„ :=Ï„ A ,Ï„ B

(5)

where Î» > 0 is a regularization parameter, and Î¦(t) is a convex regularization function. We show
that the solutions to these objectives are threshold policies, and can be fully characterized in terms
of the group-wise selection rate. We also make rigorous the notion that policies which solve the softconstraint objective interpolate between MaxUtil policies at Î» = 0 and hard-constrained policies
(DemParity or EqOpt) as Î» â†’ âˆž. This fact is clearly demonstrated by the form of the solutions in
the special case of the regularization function Î¦(t) = |t|, provided in the appendix.

4.2

Fairness Under Measurement Error

Next, consider the implications of an institution with imperfect knowledge of scores. Under a
simple model in which the estimate of an individualâ€™s score X âˆ¼ Ï€ is prone to errors e(X) such
b âˆ¼ Ï€
b . Constraining the error to be negative results in the setting
that X + e(X) := X
that scores are systematically underestimated. In this setting, it is equivalent to consider the
b to be dominated by the CDF true distribution Ï€, that is
CDF of underestimated distribution Ï€
11

P

P
â‰¤ xâ‰¥c Ï€(x) for all c âˆˆ [C]. Then we can compare the institutionâ€™s behavior under
this estimation to its behavior under the truth.
b (x)
xâ‰¥c Ï€

Proposition 4.1 (Underestimation causes underselection). Fix the distribution of B as Ï€ B and let
Î² be the acceptance rate of A when the institution makes the decision using perfect knowledge of
b A . Then
the distribution Ï€ A . Denote Î²b as the acceptance rate when the group is instead taken as Ï€
DemParity
DemParity
Î²AMaxUtil > Î²bAMaxUtil and Î²A
> Î²bA
. If the errors are further such that the true TPR
EqOpt
EqOpt
dominates the estimated TPR, it is also true that Î²A
> Î²bA
.
Because fairness criteria encourage a higher selection rate for disadvantaged groups (Corollary 3.2), systematic underestimation widens the regime of their applicability. Furthermore, since
the estimated MaxUtil policy underloans, the region for relative improvement in the outcome curve
(Figure 1) is larger, corresponding to more regimes under which fairness criteria can yield favorable
outcomes. Thus the potential for measurement error should be a factor when motivating these
criteria.

4.3

Outcome-based alternative

As explained in the preceding sections, fairness criteria may actively harm disadvantaged groups.
It is thus natural to consider a modified decision rule which involves the explicit maximization of
âˆ†ÂµA . In this case, imagine that the institutionâ€™s primary goal is to aid the disadvantaged group,
subject to a limited profit loss compared to the maximum possible expected profit U MaxUtil . The
corresponding problem is as follows.
max âˆ†ÂµA (Ï„ A ) s.t. UAMaxUtil âˆ’ U(Ï„ ) < Î´ .
Ï„A

(6)

Unlike the fairness constrained objective, this objective no longer depends on group B and instead
depends on our model of the mean score change in group A, âˆ†ÂµA .
Proposition 4.2 (Outcome-based solution). In the above setting, the optimal bank policy Ï„ A is a
threshold policy with selection rate Î² = min{Î² âˆ— , Î² max }, where Î² âˆ— is the outcome-optimal loan rate
and Î² max is the maximum loan rate under the bankâ€™s â€œbudgetâ€.
The above formulationâ€™s advantage over fairness constraints is that it directly optimizes the
outcome of A and can be approximately implemented given reasonable ability to predict outcomes.
Importantly, this objective shifts the focus to outcome modeling, highlighting the importance of
domain specific knowledge. Future work can consider strategies that are robust to outcome model
errors.

5

Optimality of Threshold Policies

Next, we move towards statements of the main theorems underlying the results presented in Section 3. We begin by establishing notation which we shall use throughout. Recall that â—¦ denotes
the Hadamard product between vectors. We identify functions mapping X â†’ R with vectors in
RC . We also define the group-wise utilities
X
Uj (Ï„ j ) :=
Ï€ j (x)Ï„ j (x)u(x) ,
(7)
xâˆˆX

12

so that for Ï„ = (Ï„ A , Ï„ B ), U(Ï„ ) := gA UA (Ï„ A ) + gB UB (Ï„ B ).
First, we formally describe threshold policies, and rigorously justify why we may always assume
without loss of generality that the institution adopts policies of this form.
Definition 5.1 (Threshold selection policy). A single group selection policy Ï„ âˆˆ [0, 1]C is called a
threshold policy if it has the form of a randomized threshold on score:
ï£±
ï£´
ï£²1, x > c
Ï„ c,Î³ = Î³, x = c , for some c âˆˆ [C] and Î³ âˆˆ (0, 1] .
(8)
ï£´
ï£³
0, x < c
As a technicality, if no members of a population have a given score x âˆˆ X , there may be
multiple threshold policies which yield equivalent selection rates for a given population. To avoid
0
0
redundancy, we introduce the notation Ï„ j âˆ¼
=Ï€P
j Ï„ j to mean that the set of scores on which Ï„ j and Ï„ j
differ has probability 0 under Ï€ j ; formally, x:Ï„ j (x)6=Ï„ j (x) Ï€ j (x) = 0. For any distribution Ï€ j , âˆ¼
=Ï€j
0
0
âˆ¼
is an equivalence relation. Moreover, we see that if Ï„ j =Ï€j Ï„ j , then Ï„ j and Ï„ j both provide the
same utility for the institution, induce the same outcomes for individuals in group j, and have the
same selection and true positive rates. Hence, if (Ï„ A , Ï„ B ) is an optimal solution to any of MaxUtil,
EqOpt, or DemParity, so is any (Ï„ 0A , Ï„ 0B ) for which Ï„ A âˆ¼
=Ï€A Ï„ 0A and Ï„ B âˆ¼
=Ï€B Ï„ 0B .
âˆ¼
For threshold policies in particular, their equivalence class under =Ï€j is uniquely determined by
the selection rate function,
X
rÏ€j (Ï„ j ) :=
Ï€ j (x)Ï„ j (x) ,
(9)
xâˆˆX

which denotes the fraction of group j which is selected. Indeed, we have the following lemma (proved
in Appendix A.1):
Lemma 5.1. Let Ï„ j and Ï„ 0j be threshold policies. Then Ï„ j âˆ¼
=Ï€j Ï„ 0j if and only if rÏ€j (Ï„ j ) = rÏ€j (Ï„ 0j ).
Further, rÏ€j (Ï„ j ) is a bijection from Tthresh (Ï€ j ) to [0, 1], where Tthresh (Ï€ j ) is the set of equivalence
âˆ’1 (Î² ) is well defined.
classes between threshold policies under âˆ¼
=Ï€j . Finally, Ï€ j â—¦ rÏ€
j
j
âˆ’1 (Î² ) is an equivalence class rather than a single policy. However, Ï€ â—¦ r âˆ’1 (Ï„ ) is
Remark that rÏ€
j
j
j
Ï€j
j
well defined, meaning that Ï€ j â—¦ Ï„ j = Ï€ j â—¦ Ï„ 0j for any two policies in the same equivalence class. Since
all quantities of interest will only depend on policies Ï„ j through Ï€ j â—¦ Ï„ j , it does not matter which
âˆ’1 (Î² ) we pick. Hence, abusing notation slightly, we shall represent T
representative of rÏ€
j
thresh (Ï€ j )
j
3
âˆ¼
by choosing one representative from each equivalence class under =Ï€j .
It turns out the policies which arise in this away are always optimal in the sense that, for a
âˆ’1 (Î² ) is the (essentially unique) policy which maximizes
given loan rate Î²j , the threshold policy rÏ€
j
j
both the institutionâ€™s utility and the utility of the group. Defining the group-wise utility,
X
Uj (Ï„ j ) :=
u(x)Ï€ j (x)Ï„ j (x) ,
(10)
xâˆˆX

we have the following result:
3

One way to do this is to consider the set of all threshold policies Ï„ c,Î³ such that, Î³ = 1 if Ï€ j (c) = 0 and Ï€ j (câˆ’1) > 0
if Î³ = 1 and c > 1.

13

Proposition 5.1 (Threshold policies are preferable). Suppose that u(x) and âˆ†(x) are strictly
increasing in x. Given any loaning policy Ï„ j for population with distribution Ï€ j , then the policy
âˆ’1 (r (Ï„ )) âˆˆ T
Ï„ thresh
:= rÏ€
Ï€j
j
thresh (Ï€ j ) satisfies
j
j
âˆ†Âµj (Ï„ thresh
) â‰¥ âˆ†Âµj (Ï„ j ) and Uj (Ï„ thresh
) â‰¥ Uj (Ï„ j ) .
j
j

(11)

Moreover, both inequalities hold with equality if and only if Ï„ j âˆ¼
.
=Ï€j Ï„ thresh
j
âˆ’1 (r (Ï„ )) can be thought of transforming an arbitrary policy Ï„ into a
The map Ï„ j 7â†’ rÏ€
Ï€j
j
j
j
threshold policy with the same selection rate. In this language, the above proposition states that
this map never reduces institution utility or individual outcomes. We can also show that optimal
MaxUtil and DemParity policies are threshold policies, as well as all EqOpt policies under an
additional assumption:

Proposition 5.2 (Existance of optimal threshold policies under fairness constraints). Suppose
that u(x) is strictly increasing in x. Then all optimal MaxUtil policies (Ï„ A , Ï„ B ) satisfy Ï„ j âˆ¼
=Ï€j
âˆ’1 r (Ï„ ) for j âˆˆ {A, B}. The same holds for all optimal DemParity policies, and if in addition
rÏ€
Ï€j
j
j
u(x)/Ï(x) is increasing, the same is true for all optimal EqOpt policies.
To prove proposition 5.1, we invoke the following general lemma which is proved using standard
convex analysis arguments (in Appendix A.2):
Lemma 5.2. Let v âˆˆ RC , and let w âˆˆ RC
>0 , and suppose either that v(x) is increasing
P in x, and
Câˆ’1
v(x)/w(x) is increasing or, âˆ€x âˆˆ X , w(x) = 0. Let Ï€ âˆˆ Simplex
and fix t âˆˆ [0, xâˆˆX Ï€(x) Â·
w(x)]. Then any
Ï„ âˆ— âˆˆ arg max hv â—¦ Ï€, Ï„ i
Ï„ âˆˆ[0,1]C

s.t.

hÏ€ â—¦ w, Ï„ i = t

(12)

âˆ’1 (r (Ï„ âˆ— )). Moreover, at least one maximizer Ï„ âˆ— âˆˆ T
satisfies Ï„ âˆ— âˆ¼
=Ï€ rÏ€
Ï€
thresh (Ï€) exists.

Proof of Proposition 5.1. We will first prove Proposition 5.1 for the function Uj . Given our nominal policy Ï„ j , let Î²j = rÏ€j (Ï„ j ). We now apply Lemma 5.2 with v(x) = u(x) and w(x) =
1. For this choice of v and w, hv, Ï„ i = Uj (Ï„ ) and that hÏ€ j â—¦ w, Ï„ = rÏ€j (Ï„ ). Then, if Ï„ j âˆˆ
âˆ’1 (r (Ï„ )).
arg maxÏ„ Uj (Ï„ ) s.t. rÏ€j (Ï„ ) = Î²j , Lemma 12 implies that Ï„ j âˆ¼
=Ï€j rÏ€
Ï€j
j
j

âˆ’1
âˆ’1
âˆ¼
On the other hand, assume that Ï„ j =Ï€j rÏ€j rÏ€j (Ï„ j ) . We show that rÏ€j (rÏ€j (Ï„ j )) is a maximizer;
âˆ’1 (r (Ï„ )) implies that U (Ï„ ) = Ï„ âˆ¼
which will imply that Ï„ j is a maximizer since Ï„ j âˆ¼
=Ï€j rÏ€
Ï€j
j
j j
j =Ï€ j
j
âˆ’1
rÏ€j (rÏ€j (Ï„ j )). By Lemma 5.2 there exists a maximizer Ï„ âˆ—j âˆˆ Tthresh (Ï€), which means that Ï„ âˆ—j =
âˆ’1 (r (Ï„ âˆ— )). Since Ï„ âˆ— is feasible, we must have r (Ï„ âˆ— ) = r (Ï„ ), and thus Ï„ âˆ— = r âˆ’1 (r (Ï„ )),
rÏ€
Ï€j
Ï€j
Ï€j
Ï€j
j
j
Ï€j
j
j
j
j
j
as needed. The same argument follows verbatim if we instead choose v(x) = âˆ†(x), and compute
hv, Ï„ i = âˆ†Âµj (Ï„ ).
We now argue Proposition 5.2 for MaxUtil, as it is a straightforward application of Lemma 5.2.
We will prove Proposition 5.2 for DemParity and EqOpt separately in Sections 6.1 and 6.2.
Proof of Proposition 5.2 for MaxUtil. MaxUtil follows from lemma 5.2 with v(x) = u(x), and
t = 0 and w = 0.

14

5.1

Quantiles and Concavity of the Outcome Curve

To further our analysis, we now introduce left and right quantile functions, allowing us to specify
thresholds in terms of both selection rate and score cutoffs.
Definition 5.2 (Upper quantile function). Define Q to be the upper quantile function corresponding to Ï€, i.e.
Qj (Î²) = argmax{c :

C
X

Ï€ j (x) > Î²}

Q+
j (Î²) := argmax{c :

and

x=c

C
X

Ï€ j (x) â‰¥ Î²} .

(13)

x=c

Crucially Q(Î²) is continuous from the right, and Q+ (Î²) is continuous from the left. Further,
Q(Â·) and Q+ (Â·) allow us to compute derivatives of key functions, like the mapping from selection
rate Î² to the group outcome associated with a policy of that rate, âˆ†Âµ(rÏ€âˆ’1 (Î²)). Because we take
Ï€ to have discrete support, all functions in this work are piecewise linear, so we shall need to
distinguish between the left and right derivatives, defined as follows
âˆ‚âˆ’ f (x) := lim

tâ†’0âˆ’

f (x + t) âˆ’ f (x)
t

and âˆ‚+ f (y) := lim

tâ†’0+

f (y + t) âˆ’ f (y)
.
t

(14)

For f supported on [a, b], we say that f is left- (resp. right-) differentiable if âˆ‚âˆ’ f (x) exists for
all x âˆˆ (a, b] (resp. âˆ‚+ f (y) exists for all y âˆˆ [a, b)). We now state the fundamental derivative
computation which underpins the results to follow:
Lemma 5.3. Let ex denote the vector such that ex (x) = 1, and ex (x0 ) = 0 for x0 6= x. Then
âˆ’1 (Î²) : [0, 1] â†’ [0, 1]C is continuous, and has left and right derivatives
Ï€ j â—¦ rÏ€
j


âˆ’1
âˆ‚+ Ï€ j â—¦ rÏ€
(Î²)
= eQ(Î²)
j

and



âˆ’1
âˆ‚âˆ’ Ï€ j â—¦ rÏ€
(Î²)
= eQ+ (Î²) .
j

(15)

The above lemma is proved in Appendix A.3. Moreover, Lemma 5.3 implies that the outcome
curve is concave under the assumption that âˆ†(x) is monotone:
âˆ’1 (Î²)) is concave. In
Proposition 5.3. Let Ï€ be a distribution over C states. Then Î² 7â†’ âˆ†Âµ(rÏ€
âˆ’1
fact, if w(x) is any non-decreasing map from X â†’ R, Î² 7â†’ hw, rÏ€ (Î²)i is concave.

Proof. Recall that a univariate function f is concave (and finite) on [a, b] if and only (a) f is left- and
right-differentiable, (b) for all x âˆˆ (a, b), âˆ‚âˆ’ f (x) â‰¥ âˆ‚+ f (x) and (c) for any x > y, âˆ‚âˆ’ f (x) â‰¤ âˆ‚+ f (y).
âˆ’1 (Î²)) = hâˆ†, Ï€ â—¦ r âˆ’1 (Î²)i. By Lemma 5.3, Ï€ â—¦ r âˆ’1 (Î²) has right and left
Observe that âˆ†Âµ(rÏ€
Ï€
Ï€
derivatives eQ(Î²) and eQ+ (Î²) . Hence, we have that
âˆ‚+ âˆ†Âµ(Î²B ) = âˆ†(Q(Î²B ))

and âˆ‚âˆ’ âˆ†Âµ(Î²B ) = âˆ†(Q+ (Î²B )) .

(16)

Using the fact that âˆ†(x) is monotone, and that Q â‰¤ Q+ , we see that âˆ‚+ âˆ†Âµ(fÏ€âˆ’1 (Î²B )) â‰¤ âˆ‚âˆ’ âˆ†Âµ(fÏ€âˆ’1 (Î²B )),
and that âˆ‚âˆ†Âµ(fÏ€âˆ’1 (Î²B )) and âˆ‚+ âˆ†Âµ(fÏ€âˆ’1 (Î²B )) are non-increasing, from which it follows that âˆ†Âµ(fÏ€âˆ’1 (Î²B ))
is concave. The general concavity result holds by replacing âˆ†(x) with w(x).

15

Utility Contour Plot
0.8





0.6



group B selection rate

1.0

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

1.0

group A selection rate

Figure 3: Considering the utility as a function of selection rates, fairness constraints correspond
to restricting the optimization to one-dimensional curves. The DemParity (DP) constraint is a
straight line with slope 1, while the EqOpt (EO) constraint is a curve given by the graph of G(Aâ†’B) .
The derivatives considered throughout Section 6 are taken with respect to the selection rate Î²A
(horizontal axis); projecting the EO and DP constraint curves to the horizontal axis recovers concave
utility curves such as those shown in the lower panel of Figure 2 (where MaxUtil in is represented
by a horizontal line through the MU optimal solution).

6

Proofs of Main Theorems

We are now ready to present and prove theorems that characterize the selection rates under fairness
constraints, namely DemParity and EqOpt. These characterizations are crucial for proving the
results in Section 3. Our computations also generalize readily to other linear constraints, in a way
that will become clear in Section 6.2.

6.1

A Characterization Theorem for DemParity

In this section, we provide a theorem that gives an explicit characterization for the range of selection
rates Î²A for A when the bank loans according to DemParity. Observe that the DemParity objective
corresponds to solving the following linear program:
max

Ï„ =(Ï„ A ,Ï„ B )âˆˆ[0,1]2C

U(Ï„ )

s.t.

hÏ€ A , Ï„ A i = hÏ€ B , Ï„ B i .

Let us introduce the auxiliary variable Î² := hÏ€ A , Ï„ A i = hÏ€ B , Ï„ B i corresponding to the selection
rate which is held constant across groups, so that all feasible solutions lie on the green DP line in
Figure 3. We can then express the following equivalent linear program:
max

Ï„ =(Ï„ A ,Ï„ B )âˆˆ[0,1]2C ,Î²âˆˆ[0,1]

U(Ï„ )

s.t.

Î² = hÏ€ j , Ï„ j i, j âˆˆ {A, B} .

This is equivalent because, for a given Î², Proposition 5.2 says that the utility maximizing policies
âˆ’1 (Î²). We now prove this:
are of the form Ï„ j = rÏ€
j
16

Proof of Proposition 5.2 for DemParity. Noting that rÏ€j (Ï„ j ) = hÏ€ j , Ï„ j i, we see that, by Lemma 5.2,
under the special case where v(x) = u(x) and w(x) = 1, the optimal solution (Ï„ âˆ—A (Î²), Ï„ âˆ—B (Î²)) for
fixed rÏ€A (Ï„ A ) = rÏ€B (Ï„ B ) = Î² can be chosen to coincide with the threshold policies. Optimizing
over Î², the global optimal must coincide with thresholds.
âˆ’1 (Î²), r âˆ’1 (Î²)), where Î²
Hence, any optimal policy is equivalent to the threshold policy Ï„ = (rÏ€
Ï€B
A
solves the following optimization:

âˆ’1
âˆ’1
max U rÏ€
(Î²), rÏ€
(Î²) .
(17)
A
B
Î²âˆˆ[0,1]

We shall show that the above expression is in fact a concave function in Î², and hence the set of
optimal selection rates can be characterized by first order conditions. This is presented formally in
the following theorem:
Theorem 6.1 (Selection rates for DemParity). The set of optimal selection rates Î² âˆ— satisfying (17)
âˆ’
+
forms a continuous interval [Î²DemParity
, Î²DemParity
], such that for any Î² âˆˆ [0, 1], we have
âˆ’
Î² < Î²DemParity
if gA u (QA (Î²)) + gB u (QB (Î²)) > 0 ,


+
+
Î² > Î²DemParity if gA u Q+
A (Î²) + gB u QB (Î²) < 0 .

Proof. Note that we can write
U

âˆ’1
âˆ’1
rÏ€
(Î²), rÏ€
(Î²)
A
B



âˆ’1 (Î²)i + g hu, Ï€ â—¦ r âˆ’1 (Î²)i .
= gA hu, Ï€ A â—¦ rÏ€
B
B
Ï€B
A


âˆ’1 (Î²), r âˆ’1 (Î²)
Since u(x) is non-decreasing in x, Proposition 5.3 implies that Î² 7â†’ U rÏ€
is
Ï€B
A
concave in Î². Hence, all optimal selection rates Î² âˆ— lie in an interval [Î² âˆ’ , Î² + ]. To further characterize
this interval, let us us compute left- and right-derivatives.

âˆ’1
âˆ’1
âˆ’1
âˆ’1
âˆ‚+ U rÏ€
(Î²), rÏ€
(Î²)
=
âˆ‚+ gA hu, Ï€ A â—¦ rÏ€
(Î²)i + âˆ‚+ gB hu, Ï€ B â—¦ rÏ€
(Î²)i
A
B
A
B


âˆ’1
âˆ’1
=
gA hu, âˆ‚+ Ï€ A â—¦ rÏ€A (Î²) i + gB hu, âˆ‚+ Ï€ B â—¦ rÏ€
(Î²) i
B
Lemma 5.3

=

gA hu, eQA (Î²) i + gB hu, eQB (Î²) i

=

gA u(QA (Î²)) + gB u(QB (Î²)) .

The same argument shows that
+
âˆ’1
âˆ’1
âˆ‚âˆ’ U((rÏ€
(Î²), rÏ€
(Î²))) = gA u(Q+
A (Î²)) + gB u(QB (Î²)).
A
B

âˆ’1 (Î²), r âˆ’1 (Î²) , a positive right derivative at Î² implies that Î² < Î² âˆ— for all Î² âˆ—
By concavity of U rÏ€
Ï€B
A
satisfying (17), and similarly, a negative left derivative at Î² implies that Î² > Î² âˆ— for all Î² âˆ— satisfying
(17).

With a result of the above form, we can now easily prove statements such as that in Corollary
3.3 (see appendix C for proofs), by fixing a selection rate of interest (e.g. Î²0 ) and inverting the
17

inequalities in Theorem 6.1 to find the exact population proportions under which, for example,
DemParity results in a higher selection rate than Î²0 .

6.2

EqOpt and General Constraints

Next, we will provide a theorem that gives an explicit characterization for the range of selection rates
Î²A for A when the bank loans according to EqOpt. Observe that the EqOpt objective corresponds
to solving the following linear program:
max

Ï„ =(Ï„ A ,Ï„ B )âˆˆ[0,1]2C

U(Ï„ )

s.t. hwA â—¦ Ï€ A , Ï„ A i = hwB â—¦ Ï€ B , Ï„ B i ,

(18)

Ï
where wj = hÏ,Ï€
. This problem is similar to the demographic parity optimization in (17), except
ji
for the fact that the constraint includes the weights. Whereas we parameterized demographic parity
solutions in terms of the acceptance rate Î² in equation (17), we will parameterize equation (18) in
terms of the true positive rate (TPR), t := hwA â—¦ Ï€ A , Ï„ A i. Thus, (18) becomes
X
max
max
gj Uj (Ï„ j ) s.t. hwj â—¦ Ï€ j , Ï„ j i = t, j âˆˆ {A, B} ,
(19)
tâˆˆ[0,tmax ] (Ï„ A ,Ï„ B )âˆˆ[0,1]2C

jâˆˆ{A,B}

where tmax = minjâˆˆ{A,B} {hÏ€ j , wj i} is the largest possible TPR. The magenta EO curve in Figure 3
illustrates that feasible solutions to this optimization problem lie on a curve parametrized by t.
Note that the objective function decouples for j âˆˆ {A, B} for the inner optimization problem,
X
max
gj Uj (Ï„ j ) s.t. hwj â—¦ Ï€ j , Ï„ j i = t .
(20)
Ï„ j âˆˆ[0,1]C

jâˆˆ{A,B}

We will now show that all optimal solutions for this inner optimization problem are Ï€ j -a.e. equal to
âˆ’1 (Î² ), depending only on the resulting selection
a policy in Tthresh (Ï€ j ), and thus can be written as rÏ€
j
j
rate.
Proof of Proposition 5.2 for EqOpt. We apply Lemma 5.2 to the inner optimization in (20) with
Ï(x)
v(x) = u(x) and w(x) = hÏ,Ï€
. The claim follows from the assumption that u(x)/Ï(x) is increasing
ji
by optimizing over t.
This selection rate Î²j is uniquely determined by the TPR t (proof appears in Appendix B.1):
Lemma 6.1. Suppose that w(x) > 0 for all x. Then the function
âˆ’1
Tj ,wj (Î²) := hrÏ€
(Î²), Ï€ j â—¦ wj i
j

is a bijection from [0, 1] to [0, hÏ€ j , wi].
Hence, for any t âˆˆ [0, tmax ], the mapping from TPR to acceptance rate, Tjâˆ’1
,wj (t), is well defined
âˆ’1
âˆ’1
and any solution to (20) is Ï€ j -a.e. equal to the policy rÏ€j (Tj ,wj (t)). Thus (19) reduces to
max
tâˆˆ[0,tmax ]

X




âˆ’1
âˆ’1
gj Uj rÏ€
T
(t)
.
j
j ,w j

jâˆˆ{A,B}

18

(21)

The above expression parametrizes the optimization problem in terms of a single variable. We
shall show that the above expression is in fact a concave function in t, and hence the set of optimal
selection rates can be characterized by first order conditions. This is presented formally in the
following theorem:
Theorem 6.2 (Selection rates for EqOpt). The set of optimal selection rates Î² âˆ— for group A satsiâˆ’
+
fying (19) forms a continuous interval [Î²EqOpt
, Î²EqOpt
], such that for any Î² âˆˆ [0, 1], we have
(Aâ†’B)

âˆ’
Î² < Î²EqOpt
if gA

u(QA (Î²))
u(QB (Gw
(Î²)))
>0,
+ gB
(Aâ†’B)
wA (QA (Î²))
wB (QB (Gw
(Î²)))
(Aâ†’B)

Î²>

+
Î²EqOpt

u(Q+
(Î²)))
u(Q+
B (Gw
A (Î²))
+ gB
if gA
<0.
+
(Aâ†’B)
+
wA (QA (Î²))
wB (QB (Gw
(Î²)))

(Aâ†’B)

âˆ’1
âˆ’1
Here, Gw
(Î²) := TB,w
(TA,w
(Î²)) denotes the (well-defined) map from selection rates Î²A for A
B
A
âˆ’1 (Î² ) and Ï„ âˆ— := r âˆ’1 (Î² ) satisfy the
to the selection rate Î²B for B such that the policies Ï„ âˆ—A := rÏ€
A
Ï€B B
B
A
constraint in (18).

Proof. Starting with the equivalent problem in (21), we use the concavity result of Lemma B.1.
Because the objective function is the positive weighted sum of two concave functions, it is also
concave. Hence, all optimal true positive rates tâˆ— lie in an interval [tâˆ’ , t+ ]. To further characterize
[tâˆ’ , t+ ], we can compute left- and right-derivatives, again using the result of Lemma B.1.


X


âˆ’1
âˆ’1
âˆ’1
âˆ’1
âˆ’1
âˆ‚+
gj Uj rÏ€
(T
(t))
= gA âˆ‚+ UA rÏ€
(TAâˆ’1
,wA (t)) + gA âˆ‚+ UA rÏ€ A (TA ,wA (t))
,w
j
j
j
A
jâˆˆ{A,B}

= gA

u(QA (TAâˆ’1
,wA (t)))
wA (QA (TAâˆ’1
,wA (t)))

+ gB

u(QB (TBâˆ’1
,wB (t)))
wB (QB (TBâˆ’1
,wB (t)))

The same argument shows that
âˆ‚âˆ’

âˆ’1
âˆ’1


u(Q+
u(Q+
B (TB ,wB (t)))
A (TA ,wA (t))
âˆ’1
âˆ’1
+
g
.
gj Uj rÏ€
(T
(t))
=
g
B
A
âˆ’1
âˆ’1
+
+
j
j ,w j
(T
(t)))
(T
(t)))
w
(Q
w
(Q
,w
,w
A
B
A
A
B
B
A
B
jâˆˆ{A,B}

X

By concavity, a positive right derivative at t implies that t < tâˆ— for all tâˆ— satisfying (21), and
similarly, a negative left derivative at t implies that t > tâˆ— for all tâˆ— satisfying (21).
Finally, by Lemma 6.1, this interval in t uniquely characterizes an interval of acceptance rates.
Thus we translate directly into a statement about the selection rates Î² for group A by seeing that
(Aâ†’B)
âˆ’1
TAâˆ’1
(Î²).
,wA (t) = Î² and TB ,wB (t) = Gw
Lastly, we remark that the results derived in this section go through verbatim for any linear
constraint of the form hw, Ï€ A â—¦ Ï„ A i = hw, Ï€ B â—¦ Ï„ B i, as long as u(x)/w(x) is increasing in x, and
w(x) > 0.

19

Repay Probability by Group
repay probability

1.0
0.8

1.0

Groups

black
white

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0
300 400 500 600 700 800

0.0

score

0.2

0.4

0.6

CDF

0.8

1.0

Figure 4: The empirical payback rates as a function of credit score and CDF for both groups from
the TransUnion TransRisk dataset.

7

Simulations

We examine the outcomes induced by fairness constraints in the context of FICO scores for two race
groups. FICO scores are a proprietary classifier widely used in the United States to predict credit
worthiness. Our FICO data is based on a sample of 301,536 TransUnion TransRisk scores from 2003
[US Federal Reserve, 2007], preprocessed by Hardt et al. [2016]. These scores, corresponding to x
in our model, range from 300 to 850 and are meant to predict credit risk. Empirical data labeled
by race allows us to estimate the distributions Ï€j , where j represents race, which is restricted to two
values: white non-Hispanic (labeled â€œwhiteâ€ in figures), and black. Using national demographic
data, we set the population proportions to be 18% and 82%.
Individuals were labeled as defaulted if they failed to pay a debt for at least 90 days on at least
one account in the ensuing 18-24 month period; we use this data to estimate the success probability
given score, Ïj (x), which we allow to vary by group to match the empirical data (see Figure 4). Our
outcome curve framework allows for this relaxation; however, this discrepancy can also be attributed
to group-dependent mismeasurement of score, and adjusting the scores accordingly would allow for
a single Ï(x). We use the success probabilities to define the affine utility and score change functions
defined in Example 2.1. We model individual penalties as a score drop of câˆ’ = âˆ’150 in the case of
a default, and in increase of c+ = 75 in the case of successful repayment.
In Figure 5, we display the empirical CDFs along with selection rates resulting from different
loaning strategies for two different settings of bank utilities. In the case that the bank experiences
a loss/profit ratio of uuâˆ’
= âˆ’10, no fairness criteria surpass the active harm rate Î²0 ; however, in
+
the case of uuâˆ’
=
âˆ’4,
DemParity
overloans, in line with the statement in Corollary 3.3.
+
These results are further examined in Figure 6, which displays the normalized outcome curves
and the utility curves for both the white and the black group. To plot the MaxUtil utility curves,
the group that is not on display has selection rate fixed at Î² MaxUtil . In this figure, the top panel
corresponds to the average change in credit scores for each group under different loaning rates Î²;
the bottom panels shows the corresponding total utility U (summed over both groups and weighted
by group population sizes) for the bank.

20

Loaning Decisions
Profit/Loss Ratio: 1/4

fraction of group above

1.0
0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

300

400

500

600

score

700

Profit/Loss Ratio: 1/10

1.0

800

0.0

Groups

Black
White

Criteria

harm
MU
DP
EO

300

400

500

600

score

700

800

Figure 5: The empirical CDFs of both groups are plotted along with the decision thresholds resulting
from MaxUtil, DemParity, and EqOpt for a model with bank utilities set to (a) uuâˆ’
= âˆ’4 and (b)
+
uâˆ’
u+ = âˆ’10. The threshold for active harm is displayed; in (a) DemParity causes active harm while
in (b) it does not. EqOpt and MaxUtil never cause active harm.
Figure 6 highlights that the position of the utility optima in the lower panel determines the loan
(selection) rates. In this specific instance, the utility and change ratios are fairly close, uuâˆ’
= âˆ’4,
+
=
âˆ’2,
meaning
that
the
bankâ€™s
profit
motivations
align
with
individual
outcomes
to
some
and ccâˆ’
+
extent. Here, we can see that EqOpt loans much closer to optimal than DemParity, similar to the
setting suggested by Corollary 3.2.
Although one might hope for decisions made under fairness constraints to positively affect
the black group, we observe the opposite behavior. The MaxUtil policy (solid orange line) and
the EqOpt policy result in similar expected credit score change for the black group. However,
DemParity (dashed green line) causes a negative expected credit score change in the black group,
corresponding to active harm. For the white group, the bank utility curve has almost the same
shape under the fairness criteria as it does under MaxUtil, the main difference being that fairness
criteria lowers the total expected profit from this group.
This behavior stems from a discrepancy in the outcome and profit curves for each population.
While incentives for the bank and positive results for individuals are somewhat aligned for the
majority group, under fairness constraints, they are more heavily misaligned in the minority group,
as seen in graphs (left) in Figure 6. We remark that in other settings where the unconstrained profit
maximization is misaligned with individual outcomes (e.g., when uuâˆ’
= âˆ’10), fairness criteria may
+
perform more favorably for the minority group by pulling the utility curve into a shape consistent
with the outcome curve.
By analyzing the resulting affects of MaxUtil, DemParity, and EqOpt on actual credit score
lending data, we show the applicability of our model to real-world applications. In particular, some
results shown in Section 3 hold empirically for the FICO TransUnion TransRisk scores.

21

Outcome Curves
Black

score change

40

White

40

20

20

0

0

-20

-20

-40

-40

-60

-60

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

Utility Curves
1.00

Black

0.75

profit

1.00

0.50

0.50

0.25

0.25

0.00

0.00

-0.25

-0.25

-0.50

-0.50

-0.75

-0.75

-1.00
0.0

0.2

0.4

0.6

0.8

selection rate

1.0

-1.00
0.0

MU
DP
EO

White

0.75

0.2

0.4

0.6

1.0

0.8

selection rate

1.0

Figure 6: The outcome and utility curves are plotted for both groups against the group selection
rates. The relative positions of the utility maxima determine the position of the decision rule
thresholds. We hold uuâˆ’
= âˆ’4 as fixed.
+

22

8

Conclusion and Future Work

We argue that without a careful model of delayed outcomes, we cannot foresee the impact a fairness
criterion would have if enforced as a constraint on a classification system. However, if such an
accurate outcome model is available, we show that there are more direct ways to optimize for
positive outcomes than via existing fairness criteria.
Our formal framework exposes a concise, yet expressive way to model outcomes via the expected
change in a variable of interest caused by an institutional decision. This leads to the natural concept
of an outcome curve that allows us to interpret and compare solutions effectively. In essence, the
formalism we propose requires us to understand the two-variable causal mechanism that translates
decisions to outcomes. Depending on the application, such an understanding might necessitate
greater domain knowledge and additional research into the specifics of the application. This is
consistent with much scholarship that points to the context-sensitive nature of fairness in machine
learning.
An interesting direction for future work is to consider other characteristics of impact beyond
the change in population mean. Variance and individual-level outcomes are natural and important considerations. Moreover, it would be interesting to understand the robustness of outcome
optimization to modeling and measurement errors.

Acknowledgements
We thank Lily Hu, Aaron Roth, and Cathy Oâ€™Neil for discussions and feedback on an earlier version
of the manuscript. We thank the students of CS294: Fairness in Machine Learning (Fall 2017,
University of California, Berkeley) for inspiring class discussions and comments on a presentation
that was a precursor of this work. This material is based upon work supported by the National
Science Foundation Graduate Research Fellowship under Grant No. DGE 1752814.

23

References
Solon Barocas and Andrew D. Selbst. Big dataâ€™s disparate impact. California Law Review, 104,
2016.
Toon Calders, Faisal Kamiran, and Mykola Pechenizkiy. Building classifiers with independency
constraints. In Proc. IEEE ICDMW, ICDMW â€™09, pages 13â€“18, 2009.
Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism
prediction instruments. FATML, 2016.
Danielle Ensign, Sorelle A Friedler, Scott Neville, Carlos Scheidegger, and Suresh Venkatasubramanian. Runaway feedback loops in predictive policing. arXiv preprint arXiv:1706.09847, 2017.
Executive Office of the President. Big data: A report on algorithmic systems, opportunity, and
civil rights. Technical report, White House, May 2016.
Dean P Foster and Rakesh V Vohra. An economic argument for affirmative action. Rationality and
Society, 4(2):176â€“188, 1992.
Andreas Fuster, Paul Goldsmith-Pinkham, Tarun Ramadorai, and Ansgar Walther. Predictably
unequal? the effects of machine learning on credit markets. SSRN, 2017.
Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In
Proc. 30th NIPS, 2016.
Lily Hu and Yiling Chen. A short-term intervention for long-term fairness in the labor market. In
Proc. 27th WWW, 2018.
Matthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. Fairness in learning:
Classic and contextual bandits. In Proc. 30th NIPS, pages 325â€“333, 2016.
Alexandra Kalev, Frank Dobbin, and Erin Kelly. Best Practices or Best Guesses? Assessing the
Efficacy of Corporate Affirmative Action and Diversity Policies. American Sociological Review,
71(4):589â€“617, 2006.
Stephen N. Keith, Robert M. Bell, August G. Swanson, and Albert P. Williams. Effects of affirmative action in medical schools. New England Journal of Medicine, 313(24):1519â€“1525, 1985.
Niki Kilbertus, Mateo Rojas-Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing,
and Bernhard SchoÌˆlkopf. Avoiding discrimination through causal reasoning. In In Proc. 30th
NIPS, pages 656â€“666, 2017.
Jon M. Kleinberg, Sendhil Mullainathan, and Manish Raghavan. Inherent trade-offs in the fair
determination of risk scores. Proc. 8th ITCS, 2017.
Matt J. Kusner, Joshua R. Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. In In
Proc. 30th NIPS, pages 4069â€“4079, 2017.
Razieh Nabi and Ilya Shpitser. Fair inference on outcomes. arXiv:1705.10378v1, 2017.

24

Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q Weinberger. On fairness
and calibration. In Advances in Neural Information Processing Systems 30, pages 5684â€“5693,
2017.
Stephen Ross and John Yinger. The Color of Credit: Mortgage Discrimination, Research Methodology, and Fair-Lending Enforcement. MIT Press, Cambridge, 2006.
US Federal Reserve. Report to the congress on credit scoring and its effects on the availability and
affordability of credit, 2007.
Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P. Gummadi. Fairness Constraints: Mechanisms for Fair Classification. In Proc. 20th AISTATS, pages 962â€“970.
PMLR, 2017.

A

Optimality of Threshold Policies

A.1

Proof of Lemma 5.1

We begin with the first statement of the lemma. Suppose Ï„ j âˆ¼
=Ï€j Ï„ 0j . Then there exists a set S âŠ‚ X
such that Ï€ j (x) = 0 for all x âˆˆ S, and for all x âˆˆ
/ S, Ï„ j (x) = Ï„ 0j (x). Thus,
rÏ€ (Ï„ j ) âˆ’ rÏ€j (Ï„ 0j ) =

X

Ï€ j (x)(Ï„ j (x) âˆ’ Ï„ 0j (x))

xâˆˆX

=

X

Ï€ j (x)(Ï„ j (x) âˆ’ Ï„ 0j (x)) = 0 .

xâˆˆS

Conversely, suppose that rÏ€j (Ï„ j ) = rÏ€j (Ï„ 0j ). Let Ï„ j = Ï„ c,Î³ and Ï„ 0j = Ï„ c0 ,Î³ 0 as in Definition 5.1. We
now have the following cases:
1. Case 1: c = c0 . Then Ï„ j (x) = Ï„ 0j (x) for all x âˆˆ X âˆ’ {c}. Hence,
0 = rÏ€ (Ï„ j ) âˆ’ rÏ€j (Ï„ 0j ) = Ï€(x)(Ï„ j (c) âˆ’ Ï„ 0j (c)) .
This implies that either Ï„ j (c) = Ï„ 0j (c), and thus Ï„ j (x) = Ï„ 0j (x) for all x âˆˆ X , or otherwise
Ï€(c) = 0, in which case we still have Ï„ j âˆ¼
=Ï€j Ï„ 0j (since the two policies agree every outside the
set {c}).
2. Case 2: c 6= c0 . We assume assume without loss of generality that c0 < c â‰¤ C. Since the
policies Ï„ c0 ,1 and Ï„ c0 +1,0 are identity for c0 < C, we may also assume without loss of generality
that Î³ 0 âˆˆ [0, 1). Thus for all x âˆˆ S := {c0 , c0 + 1, . . . , C}, we have Ï„ 0j (x) < Ï„ j (x). This implies
that
0 = rÏ€ (Ï„ j ) âˆ’ rÏ€j (Ï„ 0j )
X
=
Ï€ j (x)(Ï„ j (x) âˆ’ Ï„ 0j (x))
xâˆˆS

â‰¥ min(Ï„ j (c) âˆ’ Ï„ 0j (x)) Â·
xâˆˆS

X
xâˆˆS

25

Ï€(x) .

Since minxâˆˆS (Ï„ j (c) âˆ’ Ï„ 0j (x)) > 0, it follows that

P

xâˆˆS

Ï€ j (x) = 0, whence Ï„ j âˆ¼
=Ï€j Ï„ 0j .

Next, we show that rÏ€ is a bijection from Tthresh (Ï€) â†’ [0, 1]. That rÏ€ is injective follows
immediately from the fact if rÏ€j (Ï„ ) = rÏ€j (Ï„ 0j ), then Ï„ j âˆ¼
=Ï€j Ï„ 0j . To show it is surjective, we exhibit
for every Î² âˆˆ [0, 1] a threshold policy Ï„ c,Î³ for which rÏ€j (Ï„ c,Î³ ) = Î². We may assume Î² < 1, since
the all-ones policy has a selection rate of 1.
Recall the definition of the inverse CDF
Qj (Î²) := argmax{c :

C
X

Ï€(x) > Î²} .

x=c

Since Î² < 1, Qj (Î²) â‰¤ C. Let Î²+ =

PC

x=Qj (Î²) Ï€(x),

and let Î²âˆ’ =

PC

x=Qj (Î²)+1 Ï€(x).

Note that by

definition, we have Î²âˆ’ â‰¤ Î² < Î²+ , and Î²+ âˆ’ Î²âˆ’ = Ï€(Qj (Î²)). Hence, if we define Î³ =
have
rÏ€j (Ï„ Qj (Î²),Î³ ) = Ï€(Qj (Î²))Î³ +

C
X

Î²âˆ’Î²âˆ’
Î²+ âˆ’Î²âˆ’ ,

we

Ï€(x) = Î²âˆ’ + (Î²+ âˆ’ Î²âˆ’ )Î³ = Î²âˆ’ + Î² âˆ’ Î²âˆ’ = Î² .

x=Qj (Î²)+1

A.2

Proof of Lemma 5.2

Given Ï„ âˆˆ [0, 1]C , we define the normal cone at Ï„ as NC(Ï„ ) := ConicalHull{z : Ï„ + z âˆˆ [0, 1]C }.
We can describe NC(Ï„ ) explicitly as:
NC(Ï„ ) := {z âˆˆ RC : z i â‰¤ 0 if Ï„ i = 0, z i â‰¥ 0 if Ï„ i = 1} .
Immediately from the above definition, we have the following useful identity, which is that for any
vector g âˆˆ RC ,
ï£±
ï£´
g(x) < 0
ï£²Ï„ (x) = 0
hg, zi â‰¤ 0 âˆ€z âˆˆ NC(Ï„ ), if and only if âˆ€x âˆˆ X , Ï„ (x) = 1
(22)
g(x) > 0 .
ï£´
ï£³
Ï„ (x) âˆˆ [0, 1] g(x) = 0
Now consider the optimization problem (12). By the first order KKT conditions, we know that
b âˆˆ R such that, for all z âˆˆ NC(Ï„ âˆ— )
for any optimizer Ï„ âˆ— of the above objective, there exists some Î»
b â—¦ wi â‰¤ 0 .
hz, v â—¦ Ï€ + Î»Ï€
By (22), we must have that
ï£±
b
ï£´
Ï€(x)(v(x) + Î»w(x))
<0
ï£²0
b
Ï„ âˆ— (x) = 1
Ï€(x)(v(x) + Î»w(x)) > 0 .
ï£´
ï£³
b
âˆˆ [0, 1] Ï€(x)(v(x) + Î»w(x))
=0
Now Ï„ âˆ— (x) is not necessarily a threshold policy. To conclude the theorem, it suffices to exhibit a
threshold policy Ï„e âˆ— such that Ï„ âˆ— (x) âˆ¼
=Ï€ Ï„e âˆ— . (Note that Ï„e âˆ— (x) will also be feasible for the constraint,
and have the same objective value; hence Ï„e âˆ— will be optimal as well.)
26

b let câˆ— = min{c âˆˆ X : v(x) + Î»w(x)
b
Given Ï„ âˆ— and Î»,
â‰¥ 0}. If either (a) w(x) = 0 for all x âˆˆ X
and v(x) is strictly increasing or (b) v(x)/w(x) is strictly increasing, then the modified policy
ï£±
ï£´
x < câˆ—
ï£²0
Ï„e âˆ— (x) = Ï„ âˆ— (x) x = câˆ— ,
ï£´
ï£³
1
x > câˆ—
is a threshold policy, and Ï„ âˆ— (x) âˆ¼
=Ï€ Ï„e âˆ— . Moreover, hw, Ï„e âˆ— i = hw, Ï„e âˆ— i and hÏ€, Ï„e âˆ— i = hÏ€, Ï„e âˆ— i, which
implies that Ï„e âˆ— is an optimal policy for the objective in Lemma 5.2.

A.3

Proof of Lemma 5.3

We shall prove


âˆ’1
âˆ‚+ Ï€ j â—¦ rÏ€
(Î²)
= eQj (Î²) ,
j

(23)

where the derivative is with respect to Î². The computation of the left-derivative is analogous.
âˆ’1 (Î²) does not
Since we are concerned with right-derivatives, we shall take Î² âˆˆ [0, 1). Since Ï€ j â—¦ rÏ€
j
âˆ’1 , we can choose a cannonical representation for r âˆ’1 .
depend on the choice of representative for rÏ€
Ï€j
j
In Section A.1, we saw that the threshold policy Ï„ Qj (Î²),Î³(Î²) had acceptance rate Î², where we had
defined
C
X

Î²+ =

Ï€(x) and Î²âˆ’ =

x=Qj (Î²)

Î³(Î²) =

C
X

Ï€(x) ,

(24)

x=Qj (Î²)+1

Î² âˆ’ Î²âˆ’
.
Î²+ âˆ’ Î²âˆ’

(25)

Note then that for each x, Ï„ Qj (Î²),Î³(Î²) (x) is piece-wise linear, and thus admits left and right derivatives. We first claim that
âˆ€x âˆˆ X \ {Qj (Î²)}, âˆ‚+ Ï„ Qj (Î²),Î³(Î²) (x) = 0 .

(26)

To see this, note that Qj (Î²) is right continuous, so for all  sufficiently small, Qj (Î² + ) = Qj (Î²).
Hence, for all  sufficiently small and all x 6= Q(Î²), we have Ï„ Qj (Î²+),Î³(Î²+) (x) = Ï„ Qj (Î²+),Î³(Î²+) (x),
âˆ’1 (Î²) is supported on x = Q (Î²), and hence
as needed. Thus, Equation (26) implies that âˆ‚+ Ï€ j â—¦ rÏ€
j
j
âˆ’1
âˆ‚+ Ï€ j â—¦ rÏ€
(Î²) = âˆ‚+ Ï€ j (x)Ï„ Qj (Î²),Î³(Î²) (x)
j

x=Qj (Î²)

To conclude, we must show that âˆ‚+ Ï€ j (x)Ï„ Qj (Î²),Î³(Î²) (x)

x=Qj (Î²)

Â· eQj (Î²) .
= 1. To show this, we have

1 = âˆ‚+ (Î²)
= âˆ‚+ (rÏ€j (Ï„ Qj (Î²),Î³(Î²) ))

rÏ€j (Ï„ Qj (Î²),Î³(Î²) ) = Î² âˆ€Î² âˆˆ [0, 1)

since
!

= âˆ‚+

X

Ï€(x) Â· Ï„ Qj (Î²),Î³(Î²) (x)

xâˆˆX

27

= âˆ‚+ Ï€(x) Â· Ï„ Qj (Î²),Î³(Î²) (x)

B

x=Qj (Î²)

, as needed.

Characterization of Fairness Solutions

B.1

Derivative Computation for EqOpt

In this section, we prove Lemma 6.1, which we recall below.
Lemma 6.1. Suppose that w(x) > 0 for all x. Then the function
âˆ’1
Tj ,wj (Î²) := hrÏ€
(Î²), Ï€ j â—¦ wj i
j

is a bijection from [0, 1] to [0, hÏ€ j , wi].
We will prove Lemma 6.1 in tandem with the following derivative computation which we applied
in the proof of Theorem 6.2.
Lemma B.1. The function



âˆ’1
âˆ’1
Uj (t; wj ) := Uj rÏ€
T
(t)
j
j ,w j
is concave in t and has left and right derivatives
âˆ‚+ Uj (t; wj ) =

u(Qj (Tjâˆ’1
,wj (t)))
wj (Qj (Tjâˆ’1
,wj (t)))

and âˆ‚âˆ’ Uj (t; wj ) =

âˆ’1
u(Q+
j (Tj ,wj (t)))
âˆ’1
wj (Q+
j (Tj ,wj (t)))

.

âˆ’1 (Î²) is continuous and left and
Proof of Lemmas 6.1 and B.1. Consider a Î² âˆˆ [0, 1]. Then, Ï€ j â—¦ rÏ€
j
right differentiable by Lemma 5.3, and its left and right derivatives are indicator vectors eQj (Î²) and
âˆ’1 (Î²)i has left and right derivatives w (Q(Î²))
eQ+ (Î²) , respectively. Consequently, Î² 7â†’ hwj , Ï€ j â—¦ rÏ€
j
j
j

and wj (Q+ (Î²)), respectively; both of which are both strictly positive by the assumption w(x) > 0.
âˆ’1 (Î²)i is strictly increasing in Î², and so the map is injective. It is also
Hence, Tj ,wj (Î²) = hwj , Ï€ j â—¦ rÏ€
j
surjective because Î² = 0 induces the policy Ï„ j = 0 and Î² = 1 induces the policy Ï„ j = 1 (up to
Ï€ j -measure zero). Hence, Tj ,wj (Î²) is an order preserving bijection with left- and right-derivatives,
and we can compute the left and right derivatives of its inverse as follows:
âˆ‚+ Tjâˆ’1
,wj (t) =
and similarly, âˆ‚âˆ’ Tjâˆ’1
,wj (t) =

1
âˆ‚+ Tj ,wj (Î²)

1
.
wj (Q+ (Tjâˆ’1
,wj (t)))

=
Î²=Tjâˆ’1
,wj (t)

Then we can compute that

âˆ‚+ Uj (rÏ€j (Tjâˆ’1
,wj (t))) = âˆ‚+ U(rÏ€ j (Î²))
=

and similarly âˆ‚âˆ’ Uj (rÏ€j (Tj ,wj (t))) =

1
,
wj (Qj (Tjâˆ’1
,wj (t)))

Î²=Tjâˆ’1
,wj (t))

u(Qj (Tjâˆ’1
,wj (t)))
wj (Qj (Tjâˆ’1
,wj (t)))

âˆ’1
U (Q+
j (Tj ,wj (t)))
âˆ’1
wj (Q+
j (Tj ,wj (t)))

Â· âˆ‚+ Tj ,wj (sup(t))

.

. One can verify that for all t1 < t2 , one has that

28

âˆ’1
âˆ’1
âˆ’1
âˆ‚+ Uj (rÏ€j (Tjâˆ’1
,wj (t1 ))) â‰¥ âˆ‚âˆ’ Uj (rÏ€ j (Tj ,wj (t2 ))), and that for all t, âˆ‚+ Uj (rÏ€ j (Tj ,wj (t))) â‰¤ âˆ‚âˆ’ Uj (rÏ€ j (Tj ,wj (t))).
These facts establish that the mapping t 7â†’ Uj (rÏ€j (Tjâˆ’1
,wj (t))) is concave.

B.2

Characterizations Under Soft Constraints

Given a convex penalty Î¦ : R â†’ Râ‰¥0 , and Î» âˆˆ Râ‰¥0 , one can write down the general form for soft
constrained utility optimization
max
Ï„ =(Ï„ A ,Ï„ B )

U(Ï„ ) âˆ’ Î»Î¦(hwA â—¦ Ï€ A , Ï„ A i âˆ’ hwB â—¦ Ï€ B , Ï„ B i) ,

(27)

where wA and wB represent generic constraints. Again, we shall assume that for j âˆˆ {A, B},
u(x)/wj (x) is non-decreasing. Recall that for wj = (1, 1, . . . , 1), one recovers the soft version of
Ï
DemParity, whereas for wj = hÏ,Ï€
, one recovers the soft constrained version of EqOpt.
ji
The same argument presented in Section 6.2 shows that the optimal policies are of the form
âˆ’1
Ï„ j = rÏ€
(Tjâˆ’1
,wj (tj )) ,
j

where (tA , tB ) are solutions to the following optimization problem:
max

tA âˆˆ[0,hÏ€ A ,wA i],tB âˆˆ[0,hÏ€ B ,wB i]

âˆ’1
âˆ’1
âˆ’1
gA UA (rÏ€
(TAâˆ’1
,wA (tA ))) + gB UB (rÏ€ B (TB ,wB (tB ))) âˆ’ Î»Î¦(tA âˆ’ tB ) .
A

The following lemma gives us a first order characterization of these optimal TPRs, (tA , tB ).
Lemma B.2. All optimal policies are equivalent to threshold policies with selection rate (Î²A , Î²B )
which satisfy
iï£¹
ï£®h
u(Q+
u(QA (Î²A ))
 
A (Î²A ))
âˆ’
Î»âˆ‚
Î¦(âˆ†),
âˆ’
Î»âˆ‚
Î¦(âˆ†)
+
âˆ’
wA (QA (Î²B ))
0
wA (Q+
A (Î²A ))
iï£» ,
(28)
âˆˆ ï£°h
+
u(Q
(Î²))
u(Q
(Î²
))
0
B B
B
+ Î»âˆ‚ Î¦(âˆ†)
+ Î»âˆ‚ Î¦(âˆ†),
wB (QB (Î²B ))

âˆ’

wB (Q+
B (Î²B ))

+

where âˆ† = tA âˆ’ tB = TA ,wA (Î²A ) âˆ’ TB ,wB (Î²B ).
Proof. Let âˆ‚(Â·) denote the super-gradient set of a concave function. Note that if F is left-and-right
differentiable and concave, then âˆ‚F (x) = [âˆ‚+ F (x), âˆ‚âˆ’ F (x)]. By concavity of Uj and convexity of
Î¦, we must have that
 



X
0
âˆ’1
âˆ’1
âˆˆ âˆ‚
Uj rÏ€
T
(t
)
âˆ’ Î»Î¦(tA âˆ’ tB )
j
j
j ,w j
0
jâˆˆ{A,B}



âˆ’1 (T âˆ’1 (t )) + âˆ‚ {âˆ’Î»Î¦(t âˆ’ t )}
âˆ‚UA rÏ€
t
A
A
B
,w
A
A
A
A

=
âˆ’1 (T âˆ’1 (t )) + âˆ‚ {âˆ’Î»Î¦(t âˆ’ t )}
âˆ‚UA rÏ€
tB
B
A
B
B
B ,w B
"
#

âˆ’1 (T âˆ’1 (t )) âˆ’ Î»âˆ‚Î¦(t)
âˆ‚UA rÏ€
A
A
A ,w A
t=tA âˆ’tB

=
âˆ’1
âˆ‚UB rÏ€B (TBâˆ’1
(t
,wB B )) + Î»âˆ‚Î¦(t) t=tA âˆ’tB
"
#


âˆ’1 (T âˆ’1 (t )) âˆ’ Î»âˆ‚ Î¦(t)
âˆ’1 (T âˆ’1 (t )) âˆ’ Î»âˆ‚ Î¦(t)
r
]
[âˆ‚+ UA rÏ€
,
âˆ‚
U
+
âˆ’
âˆ’
A
A
A
,w
Ï€
,w
A
A
A
A
A
A
t=tA âˆ’tB
t=tA âˆ’tB


=
âˆ’1 (T âˆ’1 (t )) + Î»âˆ‚ Î¦(t)
âˆ’1 (T âˆ’1 (t )) + Î»âˆ‚ Î¦(t)
[âˆ‚+ UB rÏ€
,
âˆ‚
U
r
]
âˆ’
âˆ’
+
B
B
B
,w
Ï€
,w
B
B
B
B
A
A
t=t âˆ’t
t=t âˆ’t
A

29

B

A

B

ï£®

u(QA (TAâˆ’1
,wA (tA )))

ï£¯ wA (QA (TAâˆ’1
,wA (tA )))

= ï£¯
ï£° u(QB (TBâˆ’1
,wB (tB )))
wB (QB (TBâˆ’1
,wB (tB )))

ï£®h
= ï£°h

âˆ’ Î»âˆ‚+ Î¦(t)
+ Î»âˆ‚âˆ’ Î¦(t)

u(QA (Î²A ))
wA (QA (Î²A ))

âˆ’ Î»âˆ‚+ Î¦(t)

u(QB (Î²))
wB (QB (Î²B ))

+ Î»âˆ‚âˆ’ Î¦(t)

âˆ’1
u(Q+
A (TA ,wA (tA )))

t=tA âˆ’tB
t=tA âˆ’tB

,w
,

+
âˆ’1
A (QA (TA ,wA (tA )))

âˆ’1
u(Q+
B (TB ,wB (tB )))
+
wB (QB (TBâˆ’1
,wB (tB )))

u(Q+
A (Î²A ))
,
t=tA âˆ’tB wA (Q+
A (Î²B ))
u(Q+
B (Î²B ))
,
t=tA âˆ’tB wB (Q+
B (Î²B ))

âˆ’ Î»âˆ‚âˆ’ Î¦(t)
+ Î»âˆ‚+ Î¦(t)

ï£¹
âˆ’ Î»âˆ‚âˆ’ Î¦(t)
+ Î»âˆ‚+ Î¦(t)
iï£¹
t=tA âˆ’tB

t=tA âˆ’tB

ï£º
ï£º
ï£»

t=tA âˆ’tB

iï£» .

t=tA âˆ’tB

Substituting âˆ† = tA âˆ’ tB = TA ,wA (Î²A ) âˆ’ TB ,wB (Î²B ) concludes the proof.
In general, a closed form solution for the soft constrained problem may be difficult to state.
However, for the case of Î¦(t) = |t|, we can state an explicit closed form solution:
Proposition B.1 (Special case of Î¦(t) = |t|). Let Î¦(t) = |t|, fix Î», and let [Î²AÎ»,âˆ’ , Î²AÎ»,+ ] denote the
interval of optimal selection rates for Equation (27) with regularization Î». Finally, suppose that for
any optimal MaxUtil selection rates (Î²AMaxUtil , Î²BMaxUtil ), one has TA ,wA (Î²AMaxUtil ) < TB ,wB (Î²BMaxUtil ).
Let [Î²Aâˆ’ , Î²A+ ] denote the optimal loan rates in (27). Then there exists a Î»âˆ— such that, for Î» â‰¥ Î»âˆ— ,
[Î²Aâˆ’ , Î²A+ ] coincides with the hard constrained solution. Moreover, for Î» < Î»âˆ— , any Î² âˆˆ [0, 1] satifies
u(QA (Î²))
+ Ïƒâˆ— Î» > 0
wA (QA (Î²))
u(Q+
A (Î²))
if gA
+ Ïƒâˆ— Î» < 0 .
wA (Q+
A (Î²))

Î² < Î²AÎ»,âˆ’ if gA
Î² > Î²AÎ»,+

Proof. Given a set of optimal constraint values (tA , tB ) = (TA ,wA (Î²A ), TB ,wB (Î²B )) for optimal selection rates (Î²A , Î²B ) for a given parameter Î». By Proposition B.2 below, it follows that if tA = tB for
all optimal solutions, then for all Î»0 â‰¥ Î», all optimal solutions must also have tA = tB .
Hence, it suffices to show that (a) there exists a finite Î» such that all solutions must have
tA = tB , and (b) if tA 6= tB , then the display in (B.1) holds.
To prove (a) and (b), suppose tA 6= tB . By Proposition B.2 below and the fact that TA ,wA (Î² MaxUtil ) <
TB ,wB (Î²BMaxUtil ), we have tA < tB . Moreover we can compute that
ï£±
ï£´
t>0
ï£²{1}
âˆ‚Î¦(t) = [âˆ’1, 1] t = 0
ï£´
ï£³
{âˆ’1}
t<0
it follows from the first order condition in Lemma B.2 that, if tA 6= tB
u(Q+
u(QA (Î²A ))
A (Î²A ))
0âˆˆ[
+ Î»,
+ Î»] ,
+
w
wA (QA (Î²A ))
A (QA (Î²B ))

(29)

which immediately implies point (b). Point (a) follows from the above display by noting that, since
wj (x) > 0 and u(x) < âˆž for all x, where exists a Î» sufficiently large such that (29) cannot hold
for any Î²A .

30

B.3

Qualitative Behavior of Soft Constraints

We now present a proposition which formalizes the intuition that soft constraints interpolate between MaxUtil and the general hard constraint (18) in Section 6.2 (for arbitrary w, not just for
EqOpt). Because optimal policies may not be unique, we define the solution sets
P(Î») := {(Ï„ A , Ï„ B ) : (Ï„ A , Ï„ B ) solves (27) with parameter Î»} ,
with the set P(âˆž) denoting the set of solutions to (18).
At a high level, we parameterize the soft constrained solution in terms of the value of the
constraint tA = hÏ„ A , wA â—¦ Ï€ A i for A and the difference in constraint values âˆ† = hÏ„ A , wA â—¦ Ï€ A i âˆ’
hÏ„ B , wB â—¦ Ï€ B i, where (Ï„ A , Ï„ B ) âˆˆ P(Î»). We show that tA interpolates between the value of the
constraint on A at Î» = 0 and at Î» = âˆž, and that âˆ† interpolates between the difference at Î» = 0
(MaxUtil) and at âˆ† = 0 at Î» = âˆž. To be rigorous, we note that the possible values for tA and
âˆ† for each Î» are actually contiguous intervals. Hence, to make the interpolation precise, we define
the following partial order on such intervals:
Definition B.1 (Interval order). Let S1 , S2 be two intervals. We say that S1 â‰º S2 if max {x âˆˆ
S1 } < min {x âˆˆ S2 } and S1  S2 if both max {x âˆˆ S1 } â‰¤ max {x âˆˆ S2 } and min{x âˆˆ
S1 } â‰¤ min {x âˆˆ S2 }. We say that an interval-valued function S(Î») is non-decreasing (resp. non
increasing) in Î» if S(Î»)  S(Î»0 ) (resp S(Î»0 )  S(Î»0 ) for Î» â‰¤ Î»0 ).
In these terms, the interpolation of the soft constraints can be stated as follows:
Proposition B.2 (Soft constraints interpolate between MaxUtil and hard constrained solution).
Let Î¦(t) be a convex, symmetric convex function with Î¦(t) > 0 for t > 0. Then the sets
D(Î») := {âˆ† := hÏ„ A , wA â—¦ Ï€ A i âˆ’ hÏ„ B , wB â—¦ Ï€ B i : (Ï„ A , Ï„ B ) âˆˆ P(Î»)}
TA (Î») := {tA := hÏ„ A , wA â—¦ Ï€ A i|âˆƒÏ„ B : (Ï„ A , Ï„ B ) âˆˆ P(Î»)}
are closed intervals. Moreover,
1. In all cases, limÎ»â†’âˆž max{|âˆ†| âˆˆ D(Î»)} = 0.
2. If 0 âˆˆ D(Î»), then there exists a MaxUtil solution satisfying (18). Thus, for all Î» > 0,
P(Î») = P(âˆž).
3. If D(Î») â‰º {0}, then D(Î») and TA (Î») are non-decreasing on Î» âˆˆ (0, âˆž], and vice versa if
D(Î»)  {0}.
4. If D(Î») â‰º {0}, then {0} = D(âˆž)  D(Î»)  {min : âˆ† âˆˆ D(0)}, and TA (âˆž)  TA (Î»)  {min :
âˆ† âˆˆ TA (Î»)}, and vice versa if D(Î»)  {0}.
B.3.1

Proof of Proposition B.2

Again, we parameterize all solutions to the soft-constrained problem as in correspondence with
solutions (tA , tB ) to
min gA UA (tA ; wA ) + gB UB (tB ; wB ) + Î»Î¦(tA âˆ’ tB ) .

(tA ,tB )

31

Letting âˆ† := tB âˆ’ tA , we can reparameterize the above as
min gA UA (tA ; wA ) + gB UB (tA + âˆ†; wB ) âˆ’ Î»Î¦(âˆ†) .

(tA ,âˆ†)

Note then that D(Î») denotes the set of âˆ† which are partial maximimizers of the above display. If
0 âˆˆ {D(Î»)}, this implies that there exists a MaxUtil solution for which âˆ† = 0, therefore, for all
Î» > 0, all solutions will be MaxUtil solutions for which D(Î») = 0. Otherwise assume without loss
of generality that D(Î») < {0}.
First, the statement {0} = D(âˆž)  D(Î»)  {min : âˆ† âˆˆ D(0)}, and TA (âˆž)  TA (Î»)  {min :
âˆ† âˆˆ TA (Î»)}, and vice versa if D(Î»)  {0} can be solved by on a case-by-case basis. The strategy
is to show that if any of these inequalities are violated, then the associated values of âˆ† and tA are
not partial maximizers of the soft constraint objective. In particular, TA (Î») âŠ‚ [Tâˆ’ , T+ ] for some
appropriate Tâˆ’ , T+ .
We now show that D(Î») and TA (Î») are non-increasing and non-decreasing, respectively. We
shall do so invoking the following technical lemma.
Lemma B.3. Let G1 (t) be concave and let G2 (t; Î») be concave in t. Let âˆ‚G2 (t; Î») denote the
super-gradient of G2 , that is
âˆ‚G2 (t; Î») := Conv({âˆ‚âˆ’ G2 (t; Î»)} âˆª {âˆ‚âˆ’ G2 (t; Î»)})
denotes the super-gradient set of the concave mapping t 7â†’ âˆ‚G2 (t; Î»).
Then if Î» 7â†’ âˆ‚G2 (t; Î») is non-increasing (resp. non-decreasing) in Î», the interval valued function
defined below is non-increasing (resp. non-decreasing) in Î»
MAX(Î») := Î» 7â†’ arg max G1 (t) + G2 (t; Î») .
tâˆˆ[a,b]

For D(Î»), one can write any partial maximizer âˆ† as
max G1 (âˆ†) + G2 (âˆ†; Î»)
âˆ†â‰¥0

with G1 (âˆ†) = maxtA gA UA (tA ; wA ) + gB UB (tA + âˆ†; wB ) and G2 (âˆ†; Î») = Î»Î¦(âˆ†). Note that G1 (âˆ†) is
concave, being the partial maximization of a concave function, and âˆ‚G2 (âˆ†; Î») = âˆ’tâˆ‚Î¦(âˆ†). Since
âˆ‚Î¦(âˆ†)  {0} for âˆ† â‰¥ 0 (by convexity of Ï†) , we have that âˆ‚G2 (âˆ†; Î») = âˆ’tâˆ‚Î¦(âˆ†) is non-increasing
in Î». Hence Lemma B.3 implies that interval valued function D(Î») is non-increasing.
To show that TA (Î») is non-decreasing, we have that any maximizer tA can be written as
max

tA âˆˆ[Tâˆ’ ,T+ ]

G1 (tA ) + G2 (tA ; Î»)

where G1 (tA ) = gA UA (tA ; wA ) and G2 (tA ; Î») = maxâˆ†â‰¥0 gB UB (tA + âˆ†; wB ) + Î»Î¦(âˆ†). By Danskinâ€™s
theorem,
âˆ‚G2 (tA ; Î») = {âˆ‚UB (tA + âˆ†; wB ) : âˆ† âˆˆ arg max G2 (tA ; Î»)} .
Note that {âˆ† âˆˆ arg max G2 (tA ; Î»)} is non-increasing in Î» for a fixed tA , since the contribution of
the regularizer increases. Since the sets âˆ‚UB (tA + âˆ†; wB ) are themselves non-increasing in âˆ† by
32

concavity, we conclude that âˆ‚G2 (tA ; Î») is non-decreasing in Î». Hence, Lemma B.3 implies that
TA (Î») is non-decreasing in Î».
Finally, to show that max{|âˆ†| : âˆ† âˆˆ D(Î»)|} â†’ 0, Note that the left and right derivatives of
gA UA (t; wA ) and gB UB (t; wB ) are upper bounded by M whereas, since Î¦ is strictly convex, we know
that for every  > 0, min{|âˆ‚+ Î¦(âˆ†)|, |âˆ‚âˆ’ Î¦(âˆ†)|} > m() for all âˆ† : |âˆ†| > . Hence, the first order
M
optimality conditions cannot be satisfied for |âˆ†| > , and Î» > m()
, so as Î» â†’ âˆž, |âˆ†| â†’ 0.
Proof of Lemma B.3. We prove the case where âˆ‚G2 (t; Î») is non-increasing. The first order conditions requires that at an optimal t, one has
âˆ‚âˆ’ G1 (t) + âˆ‚G2 (t; Î»)âˆ’ â‰¥ 0 â‰¥ âˆ‚+ G1 (t) + âˆ‚G2 (t; Î»)+
where the super-gradients are amended to take into account boundary conditions. Suppose that
for the sake of contradiction that for Î»0 > Î», MAX(Î»0 )  MAX(Î») fails. Then, there (a) exists a
t âˆˆ MAX(Î») such that {t} â‰º MAX(Î»0 ), or (b) t âˆˆ MAX(Î»0 ) such that {t}  MAX(Î»0 ). Note that
if {t} â‰º MAX(Î»0 ), it must be the case that
âˆ‚+ G1 (t) + âˆ‚G2 (t; Î»0 )+ > 0 .
By assumption, âˆ‚âˆ’ G2 (t; Î»0 )+ â‰¤ âˆ‚0 G2 (t; Î»)+ , which implies
âˆ‚+ G1 (t) + âˆ‚G2 (t; Î»0 )+ â‰¤ âˆ‚+ G1 (t) + âˆ‚+ G2 (t; Î»)âˆ’ 0 â‰¤ 0 ,
a contradiction.

C

Proofs of Main Results

We remark that the proofs in this section rely crucially on the characterizations of the optimal
fairness-constrained policies developed in Section 6. We first define the notion of CDF domination,
which is referred to in a few of the proofs. Intuitively, it means that for any score, the fraction of
group B above this is higher than that for group A. It is realistic to assume this if we keep with
our convention that group A is the disadvantaged group relative to group B.
P
Definition
C.1
(CDF
domination).
Ï€
is
said
to
be
dominated
by
Ï€
if
âˆ€a
â‰¥
1,
A
B
x>a Ï€ A <
P
x>a Ï€ B . We denote this as Ï€ A â‰º Ï€ B .
We remark that the â‰º notation in this section is entirely unrelated to the the partial order on
intervals from Section B.3. Frequently, we shall use the following lemma:
Lemma C.1. Suppose that Ï€ A â‰º Ï€ B . Then, for all Î² > 0, it holds that QA (Î²) â‰¤ QB (Î²) and
u(QA (Î²)) â‰¤ u(QA (Î²))
Proof. The fact that QA (Î²) â‰¤ QB (Î²) follows directly from the definition of monotonicty of u implies
that u(QA (Î²)) â‰¤ u(QB (Î²)).

33

C.1

Proof of Proposition 3.1

The MaxUtil policy for group j solves the optimization
âˆ’1
max Uj (Ï„ j ) = max Uj (rÏ€
(Î²j )) .
j

Ï„ j âˆˆ[0,1]C

Î²j âˆˆ[0,1]

Computing left and right derivatives of this objective yields
âˆ’1
âˆ‚+ Uj (rÏ€
(Î²j )) = u(Qj (Î²)),
j

âˆ’1
âˆ‚âˆ’ Uj (rÏ€
(Î²j )) = u(Q+
j (Î²)) .
j

By concavity, solutions Î² âˆ— satisfy
Î² < Î²âˆ—
Î²>Î²

âˆ—

if u(Qj (Î²)) > 0 ,
if u(Q+
j (Î²)) < 0 .

(30)

Therefore, we conclude that the MaxUtil policy loans only to scores x s.t. u(x) > 0, which implies
âˆ†(x) > 0 for all scores loaned to. Therefore we must have that 0 â‰¤ âˆ†ÂµMaxUtil . By definition
âˆ†ÂµMaxUtil â‰¤ âˆ†Âµâˆ— .

C.2

Proof of Corollary 3.2

We begin with proving part (a), which gives conditions under which DemParity cases relative
improvement. Recall that Î² is the largest selection rate for which U(Î²) = U(Î²AMaxUtil ). First, we
DemParity
derive a condition which bounds the selection rate Î²A
from below. Fix an acceptance rate
MaxUtil
MaxUtil
Î² such that Î²A
< Î² < min{Î²B
, Î²}. By Theorem 6.1, we have that DemParity selects to
group A with rate higher than Î² as long as
gA â‰¤ g1 :=

1
1âˆ’

u(QA (Î²))
u(QB (Î²))

.

By (30) and the monotonicity of u, u(QA (Î²)) < 0 and u(QB (Î²)) > 0, so 0 < g1 < 1.
DemParity
Next, we derive a condition which bounds the selection rate Î²A
from above. First,
consider the case that Î²BMaxUtil < Î², and fix Î² 0 such that Î²BMaxUtil < Î² 0 < Î². Then DemParity selects
group A at a rate Î²A < Î² 0 for any proportion gA . This follows from applying Theorem 6.1 since we
+ 0
0
have that u(Q+
A (Î² )) < 0 and u(QB (Î² )) < 0 by (30) and the monotonicity of u.
MaxUtil
Instead, in the case that Î²B
> Î², fix Î² 0 such that Î² < Î² 0 < Î²BMaxUtil . Then DemParity
0
selects group A at a rate less than Î² as long as
1

gA â‰¥ g0 :=
1âˆ’

0
u(Q+
A (Î² ))
0 ))
u(Q+
(Î²
B

.

By (30) and the monotonicity of u, 0 < g0 < g1 . Thus for gA âˆˆ [g0 , g1 ], the DemParity selection
rate for group A is bounded between Î² and Î² 0 , and thus DemParity results in relative improvement.
Next, we prove part (b), which gives conditions under which EqOpt cases relative improvement.
EqOpt
First, we derive a condition which bounds the selection rate Î²A
from below. Fix an acceptance
MaxUtil
MaxUtil
(Aâ†’B)
rate Î² such that Î²A
< Î² and Î²B
>G
(Î²). By Theorem 6.2, EqOpt selects group A

34

at a rate higher than Î² as long as
gA > g3 :=

1
1âˆ’

1
Îº

Â·

Ï(QB (G(Aâ†’B) (Î²))) u(QA (Î²))
u(QB (G(Aâ†’B) (Î²))) Ï(QA (Î²))

.

By (30) and the monotonicity of u, u(QA (Î²)) < 0 and u(QB (G(Aâ†’B) (Î²))) > 0, so g3 > 0.
EqOpt
Next, we derive a condition which bounds the selection rate Î²A
from above. First, consider
the case that there exists Î² 0 such that Î² 0 < Î² and Î²BMaxUtil < G(Aâ†’B) (Î² 0 ) . Then EqOpt selects
group A at a rate less than this Î² 0 for any gA . This follows from Theorem 6.2 since we have that
+
0
(Aâ†’B) (Î² 0 ))) < 0 by (30) and the monotonicity of u.
u(Q+
A (Î² )) < 0 and u(QB (G
0
In the other case, fix Î² such that Î² < Î² 0 < Î² and Î²BMaxUtil > G(Aâ†’B) (Î² 0 ). By Theorem 6.2,
EqOpt selects group A at a rate lower than Î² 0 as long as
1

gA > g2 :=
1âˆ’

1
Îº

Â·

(Aâ†’B) (Î² 0 ))) u(Q+ (Î² 0 ))
Ï(Q+
A
B (G
+
0
u(QB (G(Aâ†’B) (Î² 0 ))) Ï(Q+
A (Î² ))

.

By (30) and the monotonicity of u, 0 < g2 < g3 . Thus for gA âˆˆ [g2 , g3 ], the EqOpt selection rate
for group A is bounded between Î² and Î² 0 , and thus EqOpt results in relative improvement.

C.3

Proof of Corollary 3.3

Recall our assumption that Î² > Î²AMaxUtil and Î²BMaxUtil > Î². As argued in the above proof of
Corollary 3.2, by (30) and the monotonicity of u, u(QA (Î²)) < 0 and u(QB (Î²)) > 0. Applying
Theorem 6.1, DemParity selects at a higher rate than Î² for any population proportion gA â‰¤ g0 ,
A (Î²))
where g0 = 1/(1 âˆ’ u(Q
u(QB (Î²)) ) âˆˆ (0, 1). In particular, if Î² = Î²0 , which we defined as the harm
âˆ’1 (Î² )) = 0 and âˆ†Âµ is decreasing at Î² ), then by the concavity of âˆ†Âµ , we
threshold (i.e. âˆ†ÂµA (rÏ€
0
0
A
A
A
âˆ’1 (Î² DemParity )) < 0, that is, DemParity causes active harm.
have that âˆ†ÂµA (rÏ€
A
A

C.4

Proof of Corollary 3.4

By Theorem 6.2, EqOpt selects at a higher rate than Î² for any population proportion gA â‰¤ g0 ,
Ï(QB (G(Aâ†’B) (Î²))) u(QA (Î²))
where g0 = 1/(1 âˆ’ Îº1 Â· u(Q
). Using our assumptions Î²BMaxUtil > G(Aâ†’B) (Î²) and
(G(Aâ†’B) (Î²))) Ï(QA (Î²))
B

Î² > Î²AMaxUtil , we have that u(QB (G(Aâ†’B) (Î²))) > 0 and u(QA (Î²)) < 0, by (30) and the monotonicity
of u. This verifies that g0 âˆˆ (0, 1). In particular, if Î² = Î²0 , then by the concavity of âˆ†ÂµA , we have
âˆ’1 (Î² EqOpt )) < 0, that is, EqOpt causes active harm.
that âˆ†ÂµA (rÏ€
A
A

C.5

Proof of Corollary 3.5

Applying Theorem 6.1, we have
âˆ’

1 âˆ’ gA
u(QA (Î²)) < u(QB (Î²)) =â‡’ Î²DemParity > Î² .
gA

35

Applying Theorem 6.2, we have:
u(QB (G(Aâ†’B) (Î²))) Â·

Ï(Q+
hÏ, Ï€ B i
1 âˆ’ gA
A (Î²))
<âˆ’
Â·
u(Q+
A (Î²)) =â‡’ Î²EqOpt < Î² .
+
(Aâ†’B)
hÏ, Ï€ A i Ï(QB (G
gA
(Î²)))

By Corollaries 3.3 and 3.4, choosing gA < g2 := 1/(1 âˆ’
(Aâ†’B) (Î²)))
Ï(Q+
B (G
(Aâ†’B) (Î²)))
u(Q+
(G
B

u(Q+
A (Î²))
Ï(Q+
A (Î²))

u(QA (Î²))
u(QB (Î²)) )

and gA > g1 := 1/(1 âˆ’

1
Îº

Â·

) satisfies the above.

P
It remains to check that g1 < g2 . Since we assumed Î² > x>ÂµA Ï€ A , we may apply Lemma C.2
to verify this.
Thus we indeed have sufficient conditions for Î²DemParity > Î² > Î²EqOpt . In particular, if Î² =
âˆ’1 (Î² EqOpt )) > 0, that is, EqOpt causes
Î²0 , then by the concavity of âˆ†ÂµA , we have that âˆ†ÂµA (rÏ€
A
A
âˆ’1 (Î² DemParity )) < 0, that is, DemParity causes active harm.
improvement, and âˆ†ÂµA (rÏ€
A
A
âˆ’1 (Î² DemParity )) > 0 =â‡’
Lastly, because Î²DemParity > Î²EqOpt , it is always true that âˆ†ÂµA (rÏ€
A
A
âˆ’1 (Î² EqOpt )) > 0, using the concavity of the outcome curve.
âˆ†ÂµA (rÏ€
A
A
Lemma C.2 (Comparison of DemParity and EqOpt selection rates). Fix Î² âˆˆ [0, 1]. Suppose Ï€ A , Ï€ B
Bi
are identical up to a translation with ÂµA < ÂµB . Also assume Ï(x) is affine in x. Denote Îº = hÏ,Ï€
hÏ,Ï€ A i .
Then,
X
Î²>
Ï€A
x>ÂµA

implies u(QB (G(Aâ†’B) (Î²))) Â· Îº Â·

Îº=

<

< u(QB (Î²)).

ÂµB
x>ÂµA Ï€ A , by lemma C.3, we must also have ÂµA
Ï(QB (Î²))
Ï(QA (Î²0 )) by linearity of expectation and linearity of Ï.

Proof. If we have Î² >
P
Px Ï€ B (x)Ï(x)
x Ï€ A (x)Ï(x)

Ï(QA (Î²))
Ï(QB (G(Aâ†’B) (Î²)))

P

ÎºÂ·

<

QB (Î²0 )
QA (Î²0 ) .

This implies

Therefore,

Ï(QA (Î²))
<1
Ï(QB (Î²0 ))

(31)
u(x)
Ï(x) is increasing in x, we
Ï(QA (Î²0 ))
B (Î²))
< Îº Â· u(Q
Ï(QB (Î²)) Â·
Ï(QB (G(Aâ†’B) (Î²0 )))

Further, using G(Aâ†’B) (Î²) > Î² from lemma C.3 and the fact that
(Aâ†’B)

(Î²)))
B (Î²))
B (G
(Aâ†’B) (Î²))) Â· Îº Â·
< u(Q
have u(Q
Ï(QB (Î²)) . Therefore, u(QB (G
Ï(QB (G(Aâ†’B) (Î²)))
Ï(QA (Î²)) < u(QB (Î²)) where the last inequality follows from (31).

We use the following technical lemma in the proof of the above lemma.
Lemma C.3. If Ï€ A , Ï€ B that are identical up to a translation with ÂµA < ÂµB , then
G(Î²) > Î² âˆ€ Î² ,
X
Âµ
QB (Î²)
Î²>
Ï€ A =â‡’ B <
.
Âµ
QA (Î²)
A
x>Âµ

(32)
(33)

Proof. For (32), observe that TPRA = Ï(ÂµA ) < TPRB = Ï(ÂµB ). For any Î², we can write QB (Î²) =
ÂµB + c and QA (Î²) = ÂµA + c for some c, since Ï€ A , Ï€ B that are identical up to translation by
36

ÂµA âˆ’ ÂµB . Thus, by computation, we can see that for Q(Î²) < Âµ, âˆ‚+ G(Aâ†’B) (Î²) > 1 and for
Q(Î²) < Âµ, âˆ‚+ G(Aâ†’B) (Î²) < 1. Since G(Aâ†’B) is monotonically increasing on [0, 1], we must have
G(Aâ†’B) (Î²) > Î² for every Î²P
âˆˆ [0, 1].
For (33), we have Î² > x>Âµ Ï€ A , we can again write QB (Î²) = ÂµB âˆ’ c and QA (Î²) = ÂµA âˆ’ c, for
some c > 0. Then it is clear than we have

C.6

ÂµB
ÂµA

<

QB (Î²)
QA (Î²) .

Proof of Corollary 3.6

Proof. Î²AMaxUtil < Î²BMaxUtil implies gA Â· u(QA (Î²AMaxUtil )) + gB Â· u(QB (Î²AMaxUtil )) > 0, which by TheoDemParity
rem 6.1, implies Î²AMaxUtil < Î²A
.
MaxUtil
MaxUtil
TPRA (Ï„
) > TPRB (Ï„
) implies G(Aâ†’B) (Î²AMaxUtil ) > Î²BMaxUtil and so
EqOpt
(Aâ†’B)
MaxUtil
u(QB (G
(Î²A
))) < 0. Therefore by Theorem 6.2, we have that Î²AMaxUtil > Î²A
.
We now give a very simple example of Ï€ A â‰º Ï€ B where Theorem 3.5 holds. The construction
of the example exemplifies the more general idea of using large in-group inequality in group A to
skew the true positive rate at MaxUtil, making TPRA (Ï„ MaxUtil ) > TPRB (Ï„ MaxUtil ).
Example C.1 (EqOpt causes relative harm). Let C = 6, and let the utility function be such that
u(4) = 0. Suppose Ï€ A (5) = 1 âˆ’ 2, Ï€ A (1) = 2 and Ï€ B (5) = 1 âˆ’ , Ï€ B (3) = .
We can easily check that Ï€ A â‰º Ï€ B . However, for any  âˆˆ (0, 1/4), we have that TPRB (Ï„ MaxUtil ) =
5(1âˆ’)
MaxUtil ) = 5(1âˆ’2) .
5(1âˆ’)+3 < TPRA (Ï„
5(1âˆ’2)+2

C.7

Proof of Proposition 4.1

b Since Ï€
b
b as Q.
b â‰º Ï€, we have Q(Î²)
Denote the upper quantile function under Ï€
â‰¤ Q(Î²). The
conclusion follows for MaxUtil and DemParity from Theorem 6.1 by the monotonicity of u.
\A (Ï„ ) âˆ€ Ï„ , that is, the true TPR dominates estimated TPR,
If we have that TPRA (Ï„ ) > TPR
the conclusion for EqOpt follows from Theorem 6.2, by the same argument as in the proof of
Corollary 3.6.

C.8

Proof of Proposition 4.2

By Proposition 5.3, Î² âˆ— = argmaxÎ² âˆ†ÂµA (Î²) exists and is unique. Î²0 = max{Î² âˆˆ [Î²AMaxUtil , 1] :
U(Î²AMaxUtil ) âˆ’ UA (Î²) â‰¤ Î´} which exists and is unique, by the continuity of âˆ†ÂµA and Proposition
5.3.

37

