WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India

Characterizing Search Intent Diversity into Click Models
∗

∗

Botao Hu1,2 , Yuchen Zhang1,2 , Weizhu Chen2,3 , Gang Wang2 , Qiang Yang3
Institute for Interdisciplinary Information Sciences, Tsinghua University, China1
Microsoft Research Asia, Beijing, China2
Hong Kong University of Science and Technology, Hong Kong3

{botao.a.hu, zhangyuc}@gmail.com, {wzchen,gawa}@microsoft.com,
{wzchen,qyang}@cse.ust.hk
ABSTRACT

logs can be collected at a very low cost, and the analysis
of them can help to understand the user’s latest preference
tendencies. Naturally, many studies have attempted to discover user preferences from click-through logs to improve the
relevance of search results [12, 11, 1].
It is well known that clicks are “informative but biased”
[4], and it is a challenging task to estimate unbiased relevance from click-through logs. One typical bias aﬀecting
user clicks is the so-called position bias: a document appearing in a higher position is more likely to attract user
clicks even though it is not as relevant as other documents
in lower positions. Thus, the click-through rate is not a
proper measure of relevance. This bias was ﬁrst noticed
by Granka et al. [7] in their eye-tracking experiment and
some follow-up investigations have been made to alleviate
this bias so that the unbiased relevance can be inferred from
the clicks. Richardson et al. [16] proposed to increase the
relevance of the documents in lower positions by using a
multiplicative factor. This idea was later formalized as the
examination hypothesis [4], which assumes that the user will
click a search result only after examining its search snippet.
In other words, given an examined document, only its relevance determines the user click. The examination hypothesis
decouples document relevance from position bias where the
position bias is formulated as the probability that a document is examined by a user. Recently, many interesting
studies have been made to reﬁne click models using the examination hypothesis. UBM[6], DBN[3], CCM[8], BBM[13],
GCM[19] are typical models which can extend the capabilities of the examination hypothesis.
The examination hypothesis assumes that, if a document
has been examined, the click-through rate of the document
for a given query is a constant number whose value is determined by the relevance between the query and the document. We argue that users with diﬀerent search intents,
however, may submit the same query to the search engine.
In other words, a single query may not truly reﬂect user
search intent. Take the query “iPad” as an example. A user
submits this query because she wants to browse general information about iPad, and the results from apple.com or
wikipedia.com are attractive to her. In contrast, another
user who submits the same query may look for information
such as user reviews or feedback on iPad. In this situation,
search results like technical reviews and discussion forums
are more likely to be clicked. This example indicates that
the attractiveness of a search result is not only inﬂuenced
by its relevance but also determined by the user’s intrinsic
search intent behind the query.

Modeling a user’s click-through behavior in click logs is a
challenging task due to the well-known position bias problem. Recent advances in click models have adopted the
examination hypothesis which distinguishes document relevance from position bias. In this paper, we revisit the
examination hypothesis and observe that user clicks cannot be completely explained by relevance and position bias.
Speciﬁcally, users with diﬀerent search intents may submit
the same query to the search engine but expect diﬀerent
search results. Thus, there might be a bias between user
search intent and the query formulated by the user, which
can lead to the diversity in user clicks. This bias has not
been considered in previous works such as UBM, DBN and
CCM. In this paper, we propose a new intent hypothesis
as a complement to the examination hypothesis. This hypothesis is used to characterize the bias between the user
search intent and the query in each search session. This hypothesis is very general and can be applied to most of the
existing click models to improve their capacities in learning unbiased relevance. Experimental results demonstrate
that after adopting the intent hypothesis, click models can
better interpret user clicks and achieve a signiﬁcant NDCG
improvement.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Retrieval
Models

General Terms
Algorithm

Keywords
Click Model, Intent Bias, Intent Diversity, Search Engine,
User Behavior

1.

INTRODUCTION

Click-through logs record user activities on search pages
and encode user preferences of search results. Click-through
∗This work was done when the authors were interns at Microsoft Research Asia.
Copyright is held by the International World Wide Web Conference Committee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28–April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

17

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India
very large scale click-though logs. Finally, the experiment
has been conducted on 3.6 million queries and one billion
search sessions, and the results illustrate the advantages of
adopting the intent hypothesis.
This paper is organized as follows: In Section 2, we brieﬂy
review the previous research on click models including their
speciﬁcations and hypotheses. In section 3, we empirically
validate that the examination hypothesis can not well interpret real click-through data. In Section 4, we propose
our intent hypothesis and its inference method. In Section
5, the experiment on real datasets shows the advantages of
adopting the proposed hypothesis. In Section 6, we analyze
the intent bias that we estimated from the experiment and
discover some insightful results.

Intent
Click Probability

Intent Bias
Query

Relevance

Document

Figure 1: The triangular relationship among intent,
query and document. The edge connecting two entities measures the degree of match between two entities.
We design an experiment to validate that the relevance
between a query and a document is not a constant number. In the experiment, we collect search sessions, and partition them into two groups according to diﬀerent search
intents. We note that after eliminating the position bias effect, most queries (96.6%) have signiﬁcantly diﬀerent clickthrough rates on two intent groups. (Please refer to Section
3 for the experimental details.) In other words, the clickthrough rate of an examined document varies greatly across
diﬀerent search sessions due to the diversity in search intent.
Figure 1 describes the triangular relationship among intent, query and document, where the edge connecting the
two entities measures the degree of match between them.
Each user presumably has an intrinsic search intent before
submitting a query. When a user comes to a search engine,
she formulates a query according to her search intent and
submits it to the search engine. The intent bias measures
how well the query matches the intent, i.e., the degree of
match between the intent and the query. The search engine
receives the query and returns a list of ranked documents,
while the relevance measures the degree of match between a
query and a document. The user examines each document
and, if a document better satisﬁes her information need, she
is more likely to click this document.
The triangular relationship suggests that the user click is
determined by both intent bias and relevance. If a user does
not clearly express her information need in the input query,
there is a large intent bias. Thus, the user is unlikely to click
the document that does not meet her search intent, even if
the document is very relevant to the query. The examination
hypothesis can be considered as a simpliﬁed case, that it
regards the search intent and the input query as equivalent
and ignores the intent bias. Thus, the relevance between a
query and a document may be mistakenly estimated when
only the examination hypothesis is adopted.
In this paper, we incorporate the concepts of intent and
intent bias to propose a novel hypothesis, the intent hypothesis, to explain how user clicks are aﬀected by intent bias,
relevance and position bias. The intent hypothesis can enhance the analytical power of the examination hypothesis,
characterize search intent diversity and interpret user clicks
better. Click models that adopt the intent hypothesis can
estimate more accurate and unbiased relevance.
This paper’s contributions are four-fold. First, we empirically demonstrate the limitations of the examination hypothesis and suggest that the position bias is not the only
bias aﬀecting click behavior. Second, we propose the novel
intent hypothesis to enhance the capability of modeling user
search behavior. Third, because the intent hypothesis is general, we apply it to two typical click models, UBM and DBN,
and adopt a Bayesian inference method to model the intent
hypothesis. This inference method is capable of learning on

2. BACKGROUND
We start by introducing deﬁnitions and notations which
will be used throughout the paper. A user submits a query
q and the search engine returns a search result page containing M (usually M = 10) documents, denoted by {dπi }M
i=1 ,
where πi is the index of the document at the i-th position.
The user examines the summary of each search result and
clicks some or none of them. Here the summary includes the
search title, snippets and URL. A search session within the
same query is called a search session, denoted by s. Clicks
on sponsored ads and other web elements are not considered in one search session. We regard subsequent query resubmission or re-formulation as a new session. The terms
url, document and result have the same meaning, and we
use them indiscriminately in the context.
We deﬁne three binary random variables, Ci , Ei and Ri to
model user click, user examination and document relevance
events at the i-th position:
• Ci : whether the user clicks on the result;
• Ei : whether the user examines the result;
• Ri : whether the document is relevant
where the ﬁrst event is observable from search sessions and
the last two events are hidden. Pr(Ci = 1) is the clickthrough rate of the i-th document, Pr(Ei = 1) is the probability of examining the i-th document, and Pr(Ri = 1) is
the relevance of the i-th document. We use the parameter
rπi to represent the document relevance as
Pr(Ri = 1) = rπi

(1)

Next, we introduce the examination hypothesis mentioned
in Section 1. The examination hypothesis was originally proposed by Richardson et al. [16] and later formalized by
Craswell et al. [4]:
Hypothesis 1 (Examination Hypothesis). A document
is clicked if and only if it is both examined and relevant,
which can be formulated as
Ei = 1, Ri = 1 ⇔ Ci = 1

(2)

where Ri and Ei are independent of each other.
Equivalently, Formula (2) can be reformulated in a probabilistic way:
Pr(Ci = 1|Ei = 1, Ri = 1) = 1
Pr(Ci = 1|Ei = 0) = 0
Pr(Ci = 1|Ri = 0) = 0

18

(3)
(4)
(5)

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India
hypothesis. DBN employs the expectation maximization algorithm to estimate parameters, which may require a great
number of iterations for convergence. Zhu et al. [19] introduced a Bayesian inference method, expectation propagation
[14], for DBN.

After summation over Ri , this hypothesis can be simpliﬁed
as
Pr(Ci = 1|Ei = 1) = rπi
Pr(Ci = 1|Ei = 0) = 0

(6)
(7)

Thus, as [16] explains, the document click-through rate is
represented by

Pr(Ei = e) Pr(Ci = 1|Ei = e)
Pr(Ci = 1) =

2.2 User Browsing Model
The user browsing model (UBM) [6] is based on the examination hypothesis but does not follow the cascade hypothesis. Instead, it assumes that the examination probability
Ei depends on the previous clicked position li = max{j ∈
{1, · · · , i − 1} | Cj = 1} as well as the distance between the
i-th position and the li -th position:

e∈{0,1}

= Pr(Ei = 1) Pr(Ci = 1|Ei = 1)





position bias

document relevance

where the position bias and the document relevance are decomposed. This hypothesis has been used in most of the
state-of-the-art click models to alleviate the position bias
problem. Next, we will brieﬂy review recent research on
click models in which DBN and UBM are used to implement the intent hypothesis in the paper.

Pr(Ei = 1|C1:i−1 ) = βli ,i−li

If there are no clicks before the position i, li is set to 0. The
likelihood of a search session under UBM can be stated in a
quite simple form:

2.1 Models Under Cascade Hypothesis

Pr(C1:M ) =

M


(rπi βli ,i−li )Ci (1 − rπi βli ,i−li )1−Ci

(16)

i=1

The cascade hypothesis was originally proposed by Craswell
et al. [4] to simulate the user search habit.

where there are M (M +1)/2 {βi,j } parameters shared across
all search sessions. The Bayesian browsing model (BBM)
[13] follows the same assumptions of UBM but adopts a
Bayesian inference algorithm.

Hypothesis 2 (Cascade Hypothesis). A user examines search results from top to bottom without skips, and the
first document is always examined:
Pr(E1 = 1) = 1
Pr(Ei+1 = 1|Ei = 0) = 0

(15)

(8)
(9)

3. REVISITING EXAMINATION HYPOTHESIS

The cascade model [4] combines the examination hypothesis and the cascade hypothesis, and it further assumes that
the user stops the examination after reaching the ﬁrst click
and abandons the search session:

As we mentioned above, the examination hypothesis is
the basis of most existing click models. The hypothesis is
mainly aimed at modeling the position bias in the click log
data. In particular, it assumes that the probability of a
click’s occurrence is uniquely determined by the query and
the document after the document is examined by the user.
In this section, we use a controlled experiment to demonstrate that the assumptions built into by the examination
hypothesis cannot completely interpret the click-through log.
We show that, given a query and an examined document,
there is still diversity among click-through rates on this document. This phenomenon clearly suggests that the position
bias is not the only bias that aﬀects click behaviors.
In order to perform the experiment, we collected clickthrough logs for one month in which each session contains
the top ten returned documents in the search result page.
We selected the search sessions that have at least one click
on the documents at positions 2 to 10. Since it is widely
believed that the user browses search results from top to
bottom, thus, from the fact that at least one of the documents at the last nine positions is clicked, we can assume
that the document at the ﬁrst position is always examined.
The search sessions are further divided into two groups with
respect to the number of clicks at the last nine positions:
one group includes sessions which have exactly one click at
the last nine positions, while another group includes sessions
which have at least two clicks at these positions. For each
search query, the click-through rate is calculated on the same
document and this document is at the ﬁrst position. We randomly chose ﬁve queries and reported the click-through rate
values on two groups of sessions in Figure 2.
According to the examination hypothesis, the relevance
between a query and a document is a constant number, if

Pr(Ei+1 = 1|Ei = 1, Ci ) = 1 − Ci

(10)

This model is too restrictive and can only deal with the
search sessions with at most one click.
The dependent click model (DCM) [9] generalizes the cascade model to sessions with multiple clicks and introduces a
set of position-dependent parameters, i.e.,
Pr(Ei+1 = 1|Ei = 1, Ci = 1) = λi
Pr(Ei+1 = 1|Ei = 1, Ci = 0) = 1

(11)
(12)

where λi represents the probability of examining the next
document after a click. These parameters are globally shared
across all search sessions. In this model, a user is simply assumed to examine all the subsequent documents below the
position of the last click. In fact, if a user is satisﬁed with
the last clicked document, she usually does not continue examining the following results.
The dynamic Bayesian network model (DBN) [3] assumes
that document attractiveness determines the user click, and
the user satisfaction determines whether the user examines
the next document. Formally speaking,
Pr(Ei+1 = 1|Ei = 1, Ci = 1) = γ(1 − sπi )
Pr(Ei+1 = 1|Ei = 1, Ci = 0) = γ,

(13)
(14)

where the parameter γ is the probability the user examines
the next document without clicks, and the parameter sπi is
the user satisfaction. Experimental comparisons show that
DBN outperforms other click models based on the cascade

19

(# clicks at position 2 to 10) = 1
(# clicks at position 2 to 10) > 1

3.0

0.6

March 28–April 1, 2011, Hyderabad, India

2.5

0.5

Density

0.3

1.0

0.2

0.1

0.0
sudoku

hulu

pac man gpa calculator
0.0

vitamins

Query

Figure 2: The document click-through rate values
on two groups of search sessions over ﬁve randomly
picked queries. One group includes sessions with
exactly one click at positions 2 to 10, and another
group includes sessions with at least two clicks at
positions 2 to 10. For each query, the click-through
rate is calculated on the same document and this
document is always at the ﬁrst position.

−0.5

0.0

0.5

1.0

Difference of click−through rates

Figure 3: The distribution of the CTR diﬀerence on
two group search sessions.
pothesis assumes that a document is clicked only after it
meets the user’s search intent, i.e. it is needed by the user.
Since the query partially reﬂects the user’s search intent, it
is reasonable to assume that a document is never needed if
it is irrelevant to the query. On the other hand, whether a
relevant document is needed is uniquely inﬂuenced by the
gap between the user’s intent and the query. From this deﬁnition, if we are sure that the user always submits the query
which exactly reﬂects her search intent, then the intent hypothesis will be reduced to the examination hypothesis.
Formally, the intent hypothesis includes the following three
statements:

the document has been examined. It implies that the clickthrough rate in the two groups should be equivalent to each
other, since the document at the top position is considered
always to be examined. As shown in Figure 2, however, none
of the queries presents the same click-through rate value on
the two groups. Instead, it is observed that the click-through
rate in the second group is signiﬁcantly higher than that
in the ﬁrst group since the P-values of t-test on these two
groups is much less than 1%.
In order to investigate the generalization of this analysis,
we subtract the click-through rate in the ﬁrst group from
that in the second group and plot the distribution of this
diﬀerence over all search queries. Figure 3 illustrates the
diﬀerence of the click-through rate values on two groups for
all queries. The resulting distribution matches a Gaussian
distribution whose center is at a positive point about 0.2.
Speciﬁcally, we found that the number of queries whose corresponding diﬀerence is located within [−0.01, 0.01] occupies
only 3.34% of all queries, which indicates that the examination hypothesis cannot precisely charaterize the click behaviors for most of the queries.
Since we believe that the users have not read the last
nine documents when they are browsing the ﬁrst document,
whether the ﬁrst document has a click is an independent
event to the click on the last nine documents. Thus, the only
possible explanation for the observed phenomenon is that
there is an intrinsic search intent behind the query and that
this intent leads to the click diversity in the two groups. In
Section 4, we will characterize this diversity by the concept
of search intent and propose the intent hypothesis for click
models.

4.

1.5

2.0

0.4

0.5

Click−through rate on the document at position 1

WWW 2011 – Session: Intent Understanding

1. The user will click a document if and only if it is examined and needed by the user.
2. If a document is irrelevant, the user will not need it.
3. If a document is relevant, whether it is needed is only
inﬂuenced by the gap between the user’s intent and
the query.
Figure 4 compares the graphical models of the examination hypothesis and the intent hypothesis. We can see in
the intent hypothesis a latent event Ni is inserted between
Ri and Ci , in order to distinguish the occurrence of being
relevant and being clicked.
Hidden:

Observed:

Ei

Ri
Ci

(a) Examination Hypothesis

Hidden:

Observed:

Ei

Ni

Ri

Ci

(b) Intent Hypothesis

Figure 4: The graphical models of the examination
hypothesis and the intent hypothesis
It order to represent the intent hypothesis in a probabilistic way, we ﬁrst introduce some symbols. Suppose that
there are m documents in the session s. The i-th document
is denoted by dπi and whether it is clicked is denoted by Ci .
Ci is a binary variable. Ci = 1 represents that the document is clicked and Ci = 0 represents that it is not clicked.
Similarly, whether the document dπi is examined, whether

MODELING INTENT DIVERSITY

4.1 Intent Hypothesis
We propose a new hypothesis called the intent hypothesis.
The intent hypothesis preserves the concept of examination
proposed by the examination hypothesis. Moreover, our hy-

20

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India
Algorithm 1 Iterative inference of unbiased model
Require: Input a set S of sessions as training data and an
original click model M (Its own parameter set is denoted
by Θ.)
1: Initialize the intent bias μs ← 1 for each session s in S.
2: repeat
3:
Phase A: We learn every parameter in Θ using the
original inference method of M while we ﬁx the values
of μs according to the latest estimated values of μs .
4:
Phase B: We estimate the value of μs for each session, using maximum-likelihood estimation, under the
learning result of parameters Θ generated in phase A.
5: until all parameters converge

it is relevant and whether it is needed are respectively represented by the binary variables Ei , Ri and Ni . Under this
deﬁnition, the intent hypothesis can be formulated as:
Ei = 1, Ni = 1 ⇔ Ci = 1
Pr(Ri = 1) = rπi
Pr(Ni = 1|Ri = 0) = 0
Pr(Ni = 1|Ri = 1) = μs

(17)
(18)
(19)
(20)

Here, rπi is the relevance of the document dπi , and μs
is deﬁned as the intent bias. Since the intent hypothesis
assumes that μs should only be inﬂuenced by the intent and
the query, μs is shared across all documents in the same
session, which means that it is a global latent variable in
session s. However, in diﬀerent sessions, the intent bias is
supposed to be diﬀerent.
After we combine (17), (18), (19) and (20), it is not diﬃcult to derive that:
Pr(Ci = 1|Ei = 1) = μs rπi
Pr(Ci = 1|Ei = 0) = 0

want to maximize is the conditional probability that the actual click events of this session occur under the speciﬁcation
of the click model, with μs being treated as the condition.
Phase A and Phase B should be executed alternatively and
iteratively until all parameters converge.
This general inference framework can be modiﬁed to be
more eﬃcient if the parameters except μs could be learned
through online Bayesian inference. In this case, the inference
is still online even after the estimations of μs are included.
Speciﬁcally, when a session is loaded, we use the posterior
distributions learned from the previous sessions to give an
estimation for μs . We then use the estimated value of μs
to update the distribution of other parameters. Since the
distribution of every parameter changes little before and after the update, we do not need to reestimate the value of
μs anymore, so that no iterative steps are needed. Thus, after all the parameters are updated, we just load in the next
session and continue the learning process.
As described in Section 2, both UBM and DBN can employ the Bayesian Paradigm to infer the parameters. According to the method mentioned above, as a new session is
loaded for training, there are three steps to execute:
1. We integrate over all the parameters except μs to derive the likelihood function Pr(C1:m |μs ).
2. We maximize this likelihood function to estimate the
value of μs .
3. Fixing the value of μs , we update other parameters by
the Bayesian inference method.
Such online Bayesian inference facilitates the single-pass
and incremental computation, which is appealing for very
large-scale data processing.

(21)
(22)

Compared to Equation (6) derived from the examination
hypothesis, Equation (21) adds a coeﬃcient μs to the original relevance rπi . Intuitively, it can be seen that we take
a μs discount oﬀ the relevance. Especially, if the value of
μs is ﬁxed to 1, it means that there will be no intent bias
and that our hypothesis will degenerate into the examination hypothesis.

4.2 Click Model Implementations
For all previous click models based on the examination
hypothesis, the switch from the examination hypothesis to
the intent hypothesis is quite simple. Actually, we only need
to replace formula (6) with formula (21) without changing
any other speciﬁcations. Here, the latent intent bias μs is
local for each session s. Every session maintains its own
intent bias, and the intent biases for diﬀerent sessions are
mutually independent.
When the intent hypothesis is adopted to construct or
reconstruct a click model M, the resulting click model is
referred to as Unbiased-M. In this paper, we choose two
state-of-the-art models, DBN and UBM, to illustrate the
impact of the intent hypothesis. The new models based on
DBN and UBM are called Unbiased-DBN and UnbiasedUBM respectively.

4.3 Inference

4.3.2 Click Prediction
Given a test session, the joint probability distribution of
click events in this session can be calculated by the following
formula.

4.3.1 Parameter Estimation
As speciﬁed above, when an unbiased model is constructed,
we estimate the value of μs for each session. After all of the
μs are known, then other parameters of the click model (such
as relevance) can be learned. However, since the estimation
of μs relies on learning the results of other parameters, the
entire inference process has deadlocks. To avoid this problem, we adopt an iterative inference as shown in Algorithm
1.
Every iteration consists of two phases. In Phase A, we
learn the click model parameter Θ based on the estimated
values of μs of the last iteration. In Phase B, we estimate
the value of μs for each session based on the parameters Θ
learned in Phase A. Here, the likelihood function that we


Pr(C1:m ) =

1

Pr(C1:m |μs )p(μs )d(μs )

(23)

0

In order to determine p(μs ), we investigate the distribution of the estimated μs in the training process and draw
a density histogram of μs for each query. Then we use the
density histogram as an approximation to p(μs ). In our
implementation, we evenly divide the range [0, 1] into 100
segments and count the density of μs that fall into each of
the segments, and then we treat this density distribution as
p(μs ).

21

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India

It is worth noting that our method is not able to predict
the exact value of the intent bias for future sessions. This is
because the intent bias can only be estimated when the actual user clicks are available, but in the testing data, the user
click is hidden and should be unknown to the click model.
Thus, we average the prediction result of future clicks over
all intent bias according to the distribution of the intent
bias counting from the training set. This averaging step
might lose the advantage of the intent hypothesis. In an
extreme case that a query never occurs in the training data,
our model will set the intent bias to be 1, where the intent
hypothesis degenerates to the examination hypothesis and
gives the same prediction result as the original model.

Since Pr(s|μs ) is a unimodal function, we can maximize
it by the ternary searching procedure on the parameter μs ,
which is in the range of [0, 1]. The optimal value for μs is
then denoted by μ∗s .
With μs optimized, we derive the posterior distributions
of each parameter θ ∈ Θ via the Bayes’ Rule:

Pr(s|Θ, μs = μ∗s )p(Θ )dΘ
p(θ|s, μs = μ∗s ) ∝ p(θ)

R|Θ |



where Θ = Θ\{θ} for short notation.
The ﬁnal step is to update p(θ) according to p(θ|s, μs =
μ∗s ). To make the whole inference process tractable, it is
usually necessary to restrict the mathematical form of p(θ)
to a speciﬁc distribution family. Here, we adopt the Probit
Bayesian Inference (PBI) proposed by Zhang et al. [18] to
implement the ﬁnal update. PBI connects each θ with an
auxiliary variable x through the probit link θ = Φ(x), and
restricts p(x) always to the Gaussian family. Thus, in order
to update p(θ), it is suﬃcient to derive p(x|μs = μ∗s ) from
p(θ|μs = μ∗s ) and approximate it by a Gaussian density.
Then we use the approximation to update p(x) and further
update p(θ). For more details, please refer to [18].
Since the learning is incremental, the update procedure is
executed once for each session.

4.4 An Example: User Browsing Model
We take the User Browsing Model (UBM) as an example to demonstrate how to apply the intent hypothesis to a
click model. A Bayesian inference procedure to estimate the
parameters is also introduced.

4.4.1 Model
Given a search session s, UBM takes the document relevances and transition probabilities as its parameters. As we
mentioned in Section 2, the parameters in a single session
M
can be denoted by Θ = {rπi }M
i=1 ∪ {βli ,i−li }i=1 . In addition,
if we want to apply the intent hypothesis to UBM, then a
new parameter should be maintained. This parameter is the
intent bias for session s, which we denote by μs . Under the
intent hypothesis, the revised version of the UBM model is
formulated by (21), (22) and (15).
According to the above model speciﬁcation, we derive the
likelihood Pr(s|Θ, μs ) for session s as :

5. EXPERIMENTS
In this section, we test the intent hypothesis with two
state-of-the-art click models, DBN and UBM, and the original examination hypothesis in DBN and UBM are replaced
by the intent hypothesis. We denote the new click models by Unbiased-UBM and Unbiased-DBN respectively. In
the experiment, we ﬁrstly use the estimated relevance from
click models to rank the documents and then evaluate the
ranking using the human labeled relevance with respect to
the normalized discounted cumulative gains (NDCG) [10].
Secondly, we use log-likelihood to evaluate how accurately
the Unbiased-UBM and Unbiased-DBN predict user future
clicks over UBM and DBN.

Pr(s|Θ, μs )  Pr(C1:M |Θ, μs )
=

1
M 


Pr(Ci | Ei = k, μs , rπi )·

(24)

i=1 k=0

Pr(Ei = k | C1:i−1 , βli ,i−li )
=

M


(μs rπi βli ,i−li )Ci (1 − μs rπi βli ,i−li )1−Ci

5.1 Experimental Setting

(25)

i=1

Training and testing datasets: The search sessions used
to train and evaluate click models were collected from a commercial search engine in the U.S. market in the English language in January 2010. A session consists of a input query,
a list of returned documents on the search result page and
a list of clicked positions. We collected the session subject
to the following constraints: (1) the search session is on the
ﬁrst result page returned by the search engine; (2) all clicks
in the session are on the search result but neither on sponsored ads nor on other web elements. In order to prevent the
whole dataset from becoming dominated by the extremely
frequent queries, we allow each query at most 106 sessions.
We also ﬁlter the search sessions to remove queries with low
frequency less than 101.5 . For each query, we sort its search
sessions according to the time stamp when the query is sent
to the search engine and split them into the training and the
testing sets at a ratio of 3:1. In total, we collect approximately one billion sessions over 3.6 million distinct queries.
The detailed information about the dataset is summarized
in Table 1.
Human judgment relevance: The manually labeled data
is used as the ground truth for evaluating the relevance estimated from click models. The human relevance system

Here, Ci represents whether the document at position i is
clicked. The overall likelihood for the entire dataset is the
product of the likelihood for every single session.

4.4.2 Parameter Estimation
We adopt the Bayesian Paradigm to infer the parameters.
The learning process is incremental: we load and process
search sessions one by one, and the data for each session
is discarded after it has been processed in the Bayesian inference. Given a new incoming session s, we update the
distribution of each parameter θ ∈ Θ based on the session
data and the click model. Before the update, each θ has a
prior distribution p(θ). We compute the likelihood function
P (s|θ) , multiply it to the prior distribution p(θ), and derive
the posterior distribution p(θ|s). Finally, the distribution of
θ is updated with respect to its posterior distribution.
Let’s examine this updating procedure in more detail.
First, we integrate the likelihood function (25) over Θ to
derive a marginal likelihood function only conditioned on
the intent bias:

Pr(s|μs ) =
p(Θ) Pr(s|Θ, μs )dΘ
R|Θ|

22

WWW 2011 – Session: Intent Understanding
Query Frequency
101.5 to 102
102 to 102.5
102.5 to 103
103 to 103.5
103.5 to 104
104 to 104.5
104.5 to 105
> 105
Total

# Query
2,503,666
782,494
241,528
740,53
21,871
6,111
1,688
616
3,632,027

March 28–April 1, 2011, Hyderabad, India
# Document
56,985,022
24,846,850
11,411,317
5,184,211
2,225,700
873,366
356,813
196,746
102,080,025

# Session
133,499,657
131,894,026
128,167,508
124,342,019
115,626,785
101,222,539
88,668,305
139,407,426
962,828,265

#HRS Query
2,402
2,410
2,132
1,869
1,317
893
471
265
11,759

# HRS Ratings
428,236
443,646
383,308
371,900
285,318
223,911
133,469
88,236
2,358,024

Table 1: The summary of the data set collected from one month of click logs.

UBM

DBN

Model
UBM
Unbiased-UBM
Improvement
DBN
Unbiased-DBN
Improvement

NDCG@1
0.578
0.660
14.14%
0.562
0.621
10.47%

NDCG@3
0.577
0.628
8.90%
0.569
0.613
7.74%

NDCG@5
0.587
0.632
7.71%
0.584
0.620
6.19%

NDCG@7
0.606
0.648
6.94%
0.604
0.636
5.22%

NDCG@10
0.596
0.633
6.25%
0.596
0.623
4.55%

Table 2: The experimental results on NDCG
evaluate the model with the intent hypothesis and with the
examination hypothesis.
18 %

(HRS) randomly picks a set of queries and requires editors
to label the relevance between these queries and their corresponding search documents. For each query-document pair,
editors give ﬁve ratings ranging from 0 to 4, corresponding
to ﬁve scales: bad, fair, good, excellent, and perfect. HRS
rating for a query-document pair is derived by averaging
the ratings of this pair from several editors. On average,
200.53 documents for a query have HRS ratings. In total,
HRS generated 2 million ratings for our data set. The last
two columns in Table 1 show the summarized HRS rating
information.

16 %
14 %
12 %
6%

8%

One important ability of the click model is to estimate
the document relevance. The trained click model is able
to provide the estimated relevance for each query-document
pair. We can rank all documents under a query according to
the estimated relevance and compare this predicted ranking
with the human judgment ranking. We expect the accuracy
of the relevance estimation can be improved after eliminating the eﬀect of the intent bias.
The normalized discounted cumulative gain (NDCG) [10]
is a well-known metric for measuring the divergence between
the predicted ranking and human judgments. NDCG is calculated cumulatively from the top of the result list to the
bottom with the gain of each result discounted at lower
ranks. Higher NDCG values correspond to a better ranking result. We report the arithmetic mean of NDCG over
multiple queries. Precisely, given a ranking, the integer sequence {gi } denotes the editorial relevances of the documents ordered by the ranking. The NDCG at a particular
rank threshold K is deﬁned as:

NDCG@3: 0.602 upon 0.532

10 %

Improvement of NDCG@3

NDCG@3: 0.586 upon 0.514

5.2 Accuracy in Relevance Estimation

NDCG@K =

Unbiased−DBN upon DBN
Unbiased−UBM upon UBM

10^1.5

10^2

10^2.5

10^3

10^3.5

10^4

10^4.5

10^5

Infinity

Query Frequency

Figure 5: The relative NDCG improvement over
query frequencies
We list NDCG evaluation results for the whole dataset
in Table 2. It shows that NDCG@1 has been improved by
14.14% from 0.578 to 0.660 for UBM and 10.47% from 0.562
to 0.621 for DBN. NDCG@10 has been improved 6.25% for
UBM and 4.55% for DBN. We clearly see that the new click
models with the intent hypothesis outperform previous models with the examination hypothesis. The lower rank threshold K is, the higher NDCG@K improvement rate achieved.
We perform the signiﬁcance test for the NDCG improvements at all ten rank threshold K’s, and ﬁnd that the Pvalues of t-test are all less than 0.01%. Therefore, we conclude that the NDCG improvement after adopting the intent
hypothesis is statistically signiﬁcant.
Furthermore, we investigate at which query frequency the
intent hypothesis contributes the greatest improvement. We

K
1  2gi − 1
Z@K i=1 log(1 + i)

where Z@K is the normalization to make the ideal ranking
(i.e. the ranking obtained by ordering the documents according to their editorial relevance) to have NDCG value of
1. We report NDCG over multiple queries using the arithmetic mean. We use the relative NDCG improvement to

23

WWW 2011 – Session: Intent Understanding
1.06

1.11

1.18

1.25

1.35

1.5

1.74

6.17

10

4%

1.02

20 %

1

March 28–April 1, 2011, Hyderabad, India
Unbiased−DBN upon DBN
Unbiased−UBM upon UBM

Unbiased−DBN upon DBN
Unbiased−UBM upon UBM

1%

10 %
0%

0%

5%

Improvement of NDCG@3

15 %

Improvement of Log−Likelihood

NDCG@3: 0.600 upon 0.52

2%

3%

NDCG@3: 0.615 upon 0.528

10^1.5

0%

10 %

20 %

30 %

40 %

50 %

60 %

70 %

80 %

90 %

10^2

10^2.5

10^3

10^3.5

10^4

10^4.5

10^5

Infinity

Query Frequency

100 %

Figure 7: The Log-likelihood improvement over
query frequencies

Percentage of queries ordered by the number of clicks per session

Figure 6: The relative NDCG improvement over average number of clicks

5.3 Accuracy in Click Prediction
After training the model, the parameters in click model
have been estimated and we can use it to predict the joint
probabilities Pr(C1:m ) for all click conﬁgurations. We evaluate the click prediction by log-likelihood (LL), which has
been widely used to measure the ﬁtness in click models such
as UBM [6] and CCM [8]. Its value indicates the logarithm
of the joint probability of user click events in testing datasets
predicted by the trained click model. A larger LL indicates better prediction accuracy, and the optimal value is
0. The improvement of LL value 1 over 2 is computed
as (exp(1 − 2 ) − 1) × 100%. We report average LL over
multiple sessions using arithmetic mean.
Figure 7 demonstrates the relative log-likelihood improvements on Unbiased-UBM and Unbiased-DBN over UBM and
DBN on diﬀerent query frequencies. For frequent queries,
the baseline model can also accurately predict clicks. So the
improvement curves drop along query frequencies. The overall improvements in log-likelihood are 2.10% for DBN and
2.96% for UBM. We can see that the performance of our
new models on log-likelihood is close to the baseline model.
As introduced in Section 4.3.2, the prediction results are
the average of cases over all intent biases according to the
distribution of intent bias computed from the training set.

plot the relative NDCG@3 improvement across diﬀerent query
frequencies for UBM and DBN in Figure 5. We can see
the NDCG improvement is very consistent across all query
frequencies. Each of the curves approximately forms an interesting unimodal pattern. In the beginning, as the query
frequency increases, the increase on NDCG improvement is
mainly because we can learn the intent bias more accurately
with the increase in data. After reaching the NDCG improvement peak at about 104 , the relevance improvement
becomes less, since the relevance estimation from the baseline model has become more accurate as more search sessions
are used for training. As we can see, the intent hypothesis
helps the baseline model with the examination hypothesis
improve the relevance estimation for most queries, especially
queries whose frequencies are between 103 to 104 .
From the analysis in Section 3, we can see that the number of clicks within a search session is related to the intent
bias, and it is interesting to see the relevance improvement
on queries with diﬀerent numbers of clicks. Thus, for each
query, we calculate the average number of clicks over all sessions. We split the query set into 10 equal subsets according
to the increasing order of the average number of clicks. We
plot the curves of the improvement rates of NDCG@3 for
these 10 subsets in Figure 6. The ten corresponding quantiles of the average number of clicks are aligned along the
x-axis above the box. From the ﬁgure, we clearly see that
the curves also have a unimodal form. As we know, a query
with lower average number of clicks tends to be navigational,
while a query with higher average number of clicks tends to
be informational. In the beginning, along with the increase
of the average number of clicks, the intent hypothesis leads
to more signiﬁcant improvement. Thus, the intent hypothesis makes the click model to more accurately characterize
informational queries, which usually have the diversity of
search intents. If the average number of clicks become large
enough, the user’s intrinsic intents will become too ambiguous to be characterized by the intent bias. Thus, after a
peak point where there is already quite large average number of clicks, the improvement will start to drop with the
increase in the average number of clicks.

6. DISCUSSION
In this section, we report several interesting ﬁndings associated with the concept of intent bias. Our study suggests
that the calculation of intent bias is not only helpful in estimating the unbiased document relevance but also allows
us to investigate more deeply some other web search mechanisms.

6.1 Intent Bias Distribution
We discovered that the sessions of informational queries
and navigational queries have signiﬁcantly diﬀerent intent
bias distributions. This property allows us to design an automatic method for classifying queries into two classes —
informational and navigational.
Let us start with two examples. In Figure 8(a), we report the density distribution of intent bias for the query

24

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India

1.0

“photosynthesis” in a density histogram. In this histogram,
the density distribution is multi-modal, which means that
the search pattern of all users can be clustered into several
groups, each with an intent bias. This observation coincides
with our intuition that in an informational query such as
“photosynthesis”, it is hard to reﬂect the exact search intent of every user. However, since a density near 1 is larger
than the density at other values, we can conclude that the
majority of users tends to click on the documents which are
relevant. In Figure 8(b), we report the density distribution
of intent bias for the query “paypal”, which is a typical navigational query. Diﬀerent from the informational query, in
this case the sessions with an intent bias near 1 dominate all
the sessions. This result is also intuitive, because we believe
that a navigational query is much more likely to precisely
reﬂect the user’s intent than an informational query.

0.0

0.2

0.4

Density

0.6

0.8

Navigational Query
Informational Query

20

0

15
Density
10

10
8

2

3

4

Entropy of intent bias distribution

Figure 9: The distribution of the entropy of the intent bias over the two groups of queries, i.e., the
informational queries and the navigational queries.

0

0

2

5

4

Density
6

1

0.0

0.2

0.4
0.6
Intent Bias

0.8

1.0

(a) query “photosynthesis”

0.0

0.2

0.4
0.6
Intent Bias

0.8

1.0

(b) query “paypal”

Figure 8: Density histogram of intent bias on the
two example queries
In order to numerically characterize the diﬀerence between
the distributions of Figure 8(a) and Figure 8(b), we calculate the entropy of the intent bias distribution for each
query. The entropy measures the degree of the diversity of
the intent biases behind a single query: a higher entropy
value suggests that the distribution of intent biases is more
diversiﬁed, while a lower entropy value suggests that the distribution is more concentrated. Obviously, the entropy for
the query “photosynthesis” (2.4611) is higher than that for
“paypal” (0.1452).
To give a more convincing conclusion, we manually chose
200 informational queries and 200 navigational queries, and
plotted the distribution of entropies on these two classes
of queries in Figure 9. It is observed that the entropy for
navigational queries is mostly located near zero, while the
entropy for informational queries are distributed around a
positive value far away from zero. This observation exactly
coincides with our intuition that there is a larger degree of
diversity in intent biases for informational queries.
The above analysis suggests that search engines can maintain a query classiﬁer based on the entropy of the intent bias.
With such a classiﬁer, the search engine can treat queries
with a single intent and with multiple intents diﬀerently so
as to satisfy the user’s information need behind the query.

6.2 Relationship between Intent Bias and Other
Click Patterns
According to the intent hypothesis, the intent bias of a
search session is deterministically derived from the click events.
Thus, there should be some speciﬁc connections between the
intent bias and other click patterns, such as the click positions and the number of clicks. In Figure 10, we report the

25

relation between intent bias and three statistical quantities,
including the ﬁrst-click position, the last-click position and
the number of clicks in the session. These quantities are averaged among all the search sessions based on three months
of data. In order to avoid the misapprehension, it is necessary to note that the higher value of μ, which is listed along
the x-axis, means the lower intent bias. For example, the
rightmost endpoint of x-axis corresponds the case that there
is no intent bias.
As illustrated in Figure 10, the ﬁrst-click position decreases as the value of μ increases. This phenomenon is
natural, since the lower the intent bias becomes, the more
similarity there is between the user’s search intent and the
query she issues. Since the search engine arranges the position of documents with respect to their similarities to the
query, a higher positioned document is more likely to have
a close connection to the query, and a higher probability of
being clicked by the user.
On the other hand, Figure 10 shows that the last-click
position decreases in the range of [0, 0.4) ∪ (0.85, 1] and increases in the range of [0.4, 0.85]. The reason for its increase
may be due to another characteristic of the search intent:
with a high intent bias, the user tends to continue browsing
the search result page and click more documents. However,
why does the last-click position dramatically decrease in the
range of (0.85, 1]? This phenomenon is caused by the existence of navigational queries. In fact, users who submit
navigational queries usually have their intent biases close to
zero, or value of μ close to 1. Most of them would be satisﬁed by the top document and leave. Thus, the last-click
position in sessions with a low intent bias is often equal to
the ﬁrst-click position.
The curve of the average number of clicks can also be interpreted in a similar way. For intent biases in the range
of [0, 0.85), most of the queries are informational, so the
users click more documents if they have higher intent biases. However, for intent biases in the range of [0.85, 1], the
navigational queries occupy a large proportion, which makes
the average number of clicks close to 1.
The interesting connection between the intent bias and
other click features makes it a valuable attribute for the

10

WWW 2011 – Session: Intent Understanding

March 28–April 1, 2011, Hyderabad, India
of China Grant 2007CB807900, 2007CB807901, the National
Natural Science Foundation of China Grant 60604033, 60553001,
61073174, 61033001 and the Hi-Tech research and Development Program of China Grant 2006AA10Z216.

7
6

[1] E. Agichtein, E. Brill, and S. Dumais. Improving web
search ranking by incorporating user behavior
information. SIGIR ’06, pages 19–26.
[2] A. Broder. A taxonomy of web search. SIGIR Forum,
36:3–10, September.
[3] O. Chapelle and Y. Zhang. A dynamic bayesian
network click model for web search ranking. WWW
’09, pages 1–10.
[4] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
WSDM ’08, pages 87–94.
[5] G. Dupret and C. Liao. A model to estimate intrinsic
document relevance from the clickthrough logs of a
web search engine. WSDM ’10, pages 181–190.
[6] G. E. Dupret and B. Piwowarski. A user browsing
model to predict search engine click data from past
observations. SIGIR ’08, pages 331–338.
[7] L. A. Granka, T. Joachims, and G. Gay. Eye-tracking
analysis of user behavior in www search. SIGIR ’04,
pages 478–479.
[8] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor,
Y.-M. Wang, and C. Faloutsos. Click chain model in
web search. WWW ’09, pages 11–20.
[9] F. Guo, C. Liu, and Y. M. Wang. Eﬃcient
multiple-click models in web search. WSDM ’09, pages
124–131.
[10] K. Järvelin and J. Kekäläinen. Cumulated gain-based
evaluation of ir techniques. ACM Trans. Inf. Syst.,
20:422–446, October.
[11] T. Joachims. Optimizing search engines using
clickthrough data. KDD ’02, pages 133–142.
[12] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and
G. Gay. Accurately interpreting clickthrough data as
implicit feedback. SIGIR ’05, pages 154–161.
[13] C. Liu, F. Guo, and C. Faloutsos. Bbm: bayesian
browsing model from petabyte-scale data. KDD ’09,
pages 537–546.
[14] T. P. Minka. Expectation propagation for approximate
bayesian inference. UAI ’01, pages 362–369.
[15] B. Piwowarski, G. Dupret, and R. Jones. Mining user
web search activity with layered bayesian networks or
how to capture a click in its context. WSDM ’2009,
pages 162–171.
[16] M. Richardson, E. Dominowska, and R. Ragno.
Predicting clicks: estimating the click-through rate for
new ads. WWW ’07, pages 521–530.
[17] R. Srikant, S. Basu, N. Wang, and D. Pregibon. User
browsing models: Relevance versus examination. KDD
’10, pages 223–232.
[18] Y. Zhang, D. Wang, G. Wang, W. Chen, Z. Zhang,
B. Hu, and L. Zhang. Learning click models via probit
bayesian inference. CIKM ’10, pages 439–448.
[19] Z. A. Zhu, W. Chen, T. Minka, C. Zhu, and Z. Chen.
A novel click model and its applications to online
advertising. WSDM ’10, pages 321–330.

5

8. REFERENCES

0

1

2

3

4

Value

8

9

Average first click position
Average last click position
Average number of clicks

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Intent bias

Figure 10: The relation between the intent bias and
three click patterns such as the average ﬁrst click
position, the average last click position and the average number of clicks.
training of ranking functions. In addition, it can also be
used for the recognition and classiﬁcation of click patterns.

7.

CONCLUSION

In this paper, we have investigated the relationship between intent, document and query and make a deep exploration of the gap between click-through rate and document
relevance. We have found that the widely adopted concepts
of the position bias and the examination hypothesis fail to
completely explain the actual bias between click-through
rate and relevance because of the gap between user search
intent and input query. In order to characterize the diversity
of search intent, we propose the intent hypothesis as a complement to the original examination hypothesis. The new
hypothesis is very general and can be ﬁt into most of the
existing click models to improve their capacities for learning unbiased relevance. Under the concept of intent bias
introduced in this paper, we have successfully modeled the
actual bias between click-through rate and relevance, whose
rationality has been veriﬁed both theoretically and empirically. Furthermore, we have demonstrated how to infer the
click models with the consideration of the intent hypothesis.
The experiments on large scale click through log show that
the models with the intent hypothesis consistently and signiﬁcantly perform better than the original versions of click
model under the examination hypothesis.
Besides user clicks, other useful information can be derived from in click through logs, such as the user’s history of
input queries and visited pages. This kind of information is
related to the user’s current search intent and can be used
to better identify the search intent behind the query. Our
next step is to include such information into the click model
with the intent hypothesis to further improve click model
accuracy.

Acknowledgment
Botao Hu would like to thank Prof. Roger Olesen of Tsinghua University for polishing the language. Botao Hu was
supported in part by the National Basic Research Program

26

